{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"day23.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gCIvz30AOj-H"},"source":["# 作業 : 觀察機器翻譯 ATTENTION 內容 \n","- 仔細地觀察機器翻譯 ATTENTION 結果"]},{"cell_type":"markdown","metadata":{"id":"usP1_X7qOv6F"},"source":["# [作業目標]\n","- 透過視覺化 注意力 attention 層 了解attention 的作用方式"]},{"cell_type":"markdown","metadata":{"id":"fWGLeN9BOxEF"},"source":["# [作業重點]\n","- 透過視覺化 注意力 attention 層 了解attention 的作用方式\n","- 原則上只要之前的訓練有跑完，這邊的程式可以執行成功最後只要觀察結果就好\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qrq_Gv7P1mPx","executionInfo":{"status":"ok","timestamp":1622121823288,"user_tz":-480,"elapsed":313,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"32b8eb61-b652-4324-c5c1-6952d4655989"},"source":["! nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Thu May 27 13:23:43 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   51C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UIBD2Nn-OI-1","executionInfo":{"status":"ok","timestamp":1622124988798,"user_tz":-480,"elapsed":250,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchtext.data.metrics import bleu_score\n","from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n","from sklearn.model_selection import train_test_split\n","import csv\n","\n","import numpy as np\n","import re\n","import random\n","import math\n","import time\n","\n","import csv\n","import spacy"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQoAR8K-RyHd","executionInfo":{"status":"ok","timestamp":1622121866739,"user_tz":-480,"elapsed":1783,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"eb01cd4f-baf2-466f-9fc0-0089e7aa4668"},"source":["# Colab 進行matplotlib繪圖時顯示繁體中文\n","# 下載字體並命名taipei_sans_tc_beta.ttf，移至指定路徑\n","!wget -O taipei_sans_tc_beta.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&export=download\n","# !mv taipei_sans_tc_beta.ttf /usr/local/lib/python3.6/dist-packages/matplotlib//mpl-data/fonts/ttf\n","\n","from matplotlib.font_manager import FontProperties\n","import matplotlib.pyplot as plt \n","plt.style.use(\"seaborn-whitegrid\")\n","import matplotlib.ticker as ticker\n","# 自定義字體變數\n","# myfont = FontProperties(fname=r'/usr/local/lib/python3/dist-packages/matplotlib/mpl-data/fonts/ttf/taipei_sans_tc_beta.ttf')\n","myfont = FontProperties(fname=r'/content/taipei_sans_tc_beta.ttf')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["--2021-05-27 13:24:25--  https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_\n","Resolving drive.google.com (drive.google.com)... 142.250.73.206, 2607:f8b0:4004:829::200e\n","Connecting to drive.google.com (drive.google.com)|142.250.73.206|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-0k-9o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ifs6mjivc4v1pbnk948icirhlp7lehnh/1622121825000/02847987870453524430/*/1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_ [following]\n","Warning: wildcards not supported in HTTP.\n","--2021-05-27 13:24:26--  https://doc-0k-9o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ifs6mjivc4v1pbnk948icirhlp7lehnh/1622121825000/02847987870453524430/*/1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_\n","Resolving doc-0k-9o-docs.googleusercontent.com (doc-0k-9o-docs.googleusercontent.com)... 172.217.2.97, 2607:f8b0:4004:80a::2001\n","Connecting to doc-0k-9o-docs.googleusercontent.com (doc-0k-9o-docs.googleusercontent.com)|172.217.2.97|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/x-font-ttf]\n","Saving to: ‘taipei_sans_tc_beta.ttf’\n","\n","taipei_sans_tc_beta     [ <=>                ]  19.70M  --.-KB/s    in 0.1s    \n","\n","2021-05-27 13:24:27 (141 MB/s) - ‘taipei_sans_tc_beta.ttf’ saved [20659344]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BrbNQhl5R2MP","executionInfo":{"status":"ok","timestamp":1622121989898,"user_tz":-480,"elapsed":19772,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"97b21daa-aad4-434c-9278-3c517ddc60a5"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wFjVGqegR5U8","executionInfo":{"status":"ok","timestamp":1622122024436,"user_tz":-480,"elapsed":1785,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"db10f0e2-3141-4f74-ae84-2b42c21b67c6"},"source":["data_dir = '/content/drive/My Drive/Colab Notebooks/NLP_course/day23/data/'\n","lines = open(data_dir + 'cmn.txt' , encoding='utf-8').read().strip().split('\\n')\n","trnslt_pairs = [[s for s in l.split('\\t')] for l in lines ]\n","print (\"Sample: \" , trnslt_pairs[1000][0:2] )\n","print (\"Total records:\" , len(trnslt_pairs))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Sample:  ['He was drowned.', '他被淹死了。']\n","Total records: 24360\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osAId_O_-Zpj","executionInfo":{"status":"ok","timestamp":1622122042723,"user_tz":-480,"elapsed":510,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"965034a3-aa8d-4d58-b461-cf234b7d191e"},"source":["train, test = train_test_split(trnslt_pairs, test_size=0.08)\n","train, val = train_test_split(train, test_size=0.09)\n","print (\"training data:{} , develop data: {} , testing data: {}\".format(len(train),len(val),len(test)))\n","    \n","def write_csv(trn_data, file_path ):\n","    with open(file_path ,'w', newline='', encoding='utf-8') as fout:\n","        writer = csv.writer (fout)\n","        for itm in trn_data: \n","            writer.writerow ([itm[0],itm[1]])\n","            \n","# file_path = data_dir + 'train.csv'\n","# write_csv(train, file_path )\n","\n","# file_path = data_dir + 'val.csv'\n","# write_csv(val, file_path )\n","    \n","# file_path = data_dir + 'test.csv'\n","# write_csv(test, file_path )"],"execution_count":6,"outputs":[{"output_type":"stream","text":["training data:20394 , develop data: 2017 , testing data: 1949\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tl-KIM-nSA-H","executionInfo":{"status":"ok","timestamp":1622122051749,"user_tz":-480,"elapsed":1861,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}}},"source":["# 下載 spacy 的英文模型 幫我們做tokenize\n","model_dir =  '/content/drive/My Drive/Colab Notebooks/NLP_course/day23/model/'\n","\n","spacy_eng = spacy.load('en_core_web_sm')\n","def tokenize_eng(text):\n","  #清除不需要的字符\n","  text = re.sub(r\"([.!?])\", r\" \\1\", text)\n","  return [tok.text for tok in spacy_eng.tokenizer(text)]\n","\n","TRG = Field(tokenize = tokenize_eng, \n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = True)\n","\n","\n","#spacy_zh = spacy.load('zh_core_web_sm')\n","def tokenize_cmn(text):\n","  #去掉非中文字元\n","  regex = re.compile(r'[^\\u4e00-\\u9fa5A-Za-z0-9]')\n","  text = regex.sub(' ', text)\n","\n","  return [word for word in text if word.strip()]\n","  # return [word for word in tok.text for tok in spacy_en.tokenizer(text)]\n","\n","SRC = Field(tokenize = tokenize_cmn, \n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = True, \n","            include_lengths = True)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"sVwfCUhjIjHB","executionInfo":{"status":"ok","timestamp":1622122696640,"user_tz":-480,"elapsed":641426,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}}},"source":["train_dataset, dev_dataset, test_dataset = TabularDataset.splits(\n","    path = data_dir , format = 'csv', skip_header = True,\n","    train='train.csv', validation='val.csv', test='test.csv',\n","    fields=[\n","        ('trg', TRG),\n","        ('src', SRC)\n","    ]\n",")"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HgtIHqEwCXrQ","executionInfo":{"status":"ok","timestamp":1622122720931,"user_tz":-480,"elapsed":528,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"b127b2d8-79fe-4f19-c4f3-f472a225b42e"},"source":["# 讀取之前儲存的 vocabulary\n","SRC.build_vocab(train_dataset, min_freq=1)\n","TRG.build_vocab(train_dataset, min_freq=1)\n","# SRC.vocab = torch.load(model_dir + 'SRC_vocab.pt')\n","# TRG.vocab = torch.load(model_dir + 'TRG_vocab.pt')\n","\n","print (\"中文語料的字元表長度: \" , len(SRC.vocab) , \", 英文的字元表長度: \" ,len(TRG.vocab))\n","print (\"Sample SRC:\", test_dataset[0].src , \"TRG:\", test_dataset[0].trg)\n","\n","BATCH_SIZE = 128\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","    (train_dataset, dev_dataset, test_dataset), \n","     batch_size = BATCH_SIZE,\n","     sort_within_batch = True,\n","     sort_key = lambda x : len(x.src),\n","     device = device)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["中文語料的字元表長度:  3356 , 英文的字元表長度:  6196\n","Sample SRC: ['他', '們', '休', '息', '了', '一', '會', '兒'] TRG: ['they', 'had', 'a', 'rest', 'for', 'a', 'while', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lYoqlKcrq2Z_"},"source":["# 模型主體 和前面範例程式一樣\n","\n"]},{"cell_type":"code","metadata":{"id":"wj3ZTHDMSGOF","executionInfo":{"status":"ok","timestamp":1622122738316,"user_tz":-480,"elapsed":379,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}}},"source":["class Attention(nn.Module):\n","  def __init__(self, enc_hid_dim, dec_hid_dim):\n","    super().__init__()\n","\n","  def forward(self, hidden, encoder_outputs, mask):\n","    # hidden bz , dec_hid_dim\n","    # encoder_outputs src len, bz , enc_hid_dim x 2\n","    # mask bz , src len\n","    \n","    batch_size = encoder_outputs.shape[1]\n","    src_len = encoder_outputs.shape[0]\n","\n","    hidden = hidden.unsqueeze(1) \n","    # hidden unsqueeze bz , 1 , dec_hid_dim\n","\n","    attention = torch.matmul( hidden , encoder_outputs.permute(1, 2, 0)   )\n","    # attention bz, 1 , src len\n","    \n","    attention = attention.squeeze(1)\n","    # squeeze bz , src len\n","\n","    attention = attention.masked_fill(mask == 0, -1e10)\n","\n","    return F.softmax(attention, dim = 1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"TNzgZqHcS2CX","executionInfo":{"status":"ok","timestamp":1622122738814,"user_tz":-480,"elapsed":2,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}}},"source":["class RNNEncoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        # 雙向 ＧＲＵ encoder \n","        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n","        \n","        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, src, src_len):\n","        \n","        #src shape [src len, batch size]\n","        #src_len shape [batch size]\n","        \n","        embedded = self.dropout(self.embedding(src))\n","        \n","        #embedded shape [src len, batch size, emb dim]\n","                \n","        # 使用pack_padded_sequence 來壓縮序列        \n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len)\n","                \n","        packed_outputs, hidden = self.rnn(packed_embedded)\n","\n","        # 使用 pad_packed_sequence 用來展開序列成原本形狀的      \n","        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n","            \n","            \n","        #outputs shape [src len, batch size, hid dim * num directions]\n","        #hidden shape [n layers * num directions, batch size, hid dim]\n","        \n","        #hidden 堆疊 [forward_1, backward_1, forward_2, backward_2, ...]\n","        #outputs 是最後一層 \n","        \n","        #hidden [-2, :, : ] 是最後一層 forwards RNN \n","        #hidden [-1, :, : ] 是最後一層 backwards RNN\n","        \n","        # hidden 是最後再過一層 dense layer\n","        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n","        \n","        #outputs shape [src len, batch size, enc hid dim * 2]\n","        #hidden shape [batch size, dec hid dim]\n","        \n","        return outputs, hidden\n","\n","class RNNDecoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n","        super().__init__()\n","\n","        self.output_dim = output_dim\n","        self.attention = attention\n","        \n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        \n","        # 單向 ＧＲＵ decoder \n","        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n","        \n","        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, input, hidden, encoder_outputs, mask):\n","             \n","        #input shape [batch size]\n","        #hidden shape [batch size, dec hid dim]\n","        #encoder_outputs shape [src len, batch size, enc hid dim * 2]\n","        #mask shape [batch size, src len]\n","        \n","        input = input.unsqueeze(0)\n","        \n","        #input shape [1, batch size]\n","        \n","        embedded = self.dropout(self.embedding(input))\n","        \n","        #embedded shape [1, batch size, emb dim]\n","        \n","        a = self.attention(hidden, encoder_outputs, mask)\n","                \n","        #a shape [batch size, src len]\n","        \n","        a = a.unsqueeze(1)\n","        \n","        #a shape [batch size, 1, src len]\n","        \n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        \n","        #encoder_outputs shape [batch size, src len, enc hid dim * 2]\n","        \n","        weighted = torch.bmm(a, encoder_outputs)\n","        \n","        #weighted shape [batch size, 1, enc hid dim * 2]\n","        \n","        weighted = weighted.permute(1, 0, 2)\n","        \n","        #weighted shape [1, batch size, enc hid dim * 2]\n","        \n","        rnn_input = torch.cat((embedded, weighted), dim = 2)\n","        \n","        #rnn_input shape [1, batch size, (enc hid dim * 2) + emb dim]\n","            \n","        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n","        \n","        #output shape [seq len, batch size, dec hid dim * n directions]\n","        #hidden shape [n layers * n directions, batch size, dec hid dim]\n","        \n","        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n","        #output shape [1, batch size, dec hid dim]\n","        #hidden shape [1, batch size, dec hid dim]\n","        #this also means that output == hidden\n","        assert (output == hidden).all()\n","        \n","        embedded = embedded.squeeze(0)\n","        output = output.squeeze(0)\n","        weighted = weighted.squeeze(0)\n","        \n","        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n","        \n","        #prediction shape [batch size, output dim]\n","        \n","        return prediction, hidden.squeeze(0), a.squeeze(1)\n","\n","class Seq2SeqATTN(nn.Module):\n","    def __init__(self, encoder, decoder, src_pad_idx, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.src_pad_idx = src_pad_idx\n","        self.device = device\n","        \n","    def create_mask(self, src):\n","        mask = (src != self.src_pad_idx).permute(1, 0)\n","        return mask\n","        \n","    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n","        \n","        #src = [src len, batch size]\n","        #src_len = [batch size]\n","        #trg = [trg len, batch size]\n","        #teacher_forcing_ratio is probability to use teacher forcing\n","        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n","                    \n","        batch_size = src.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","        \n","        #tensor to store decoder outputs\n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","        \n","        #encoder_outputs is all hidden states of the input sequence, back and forwards\n","        #hidden is the final forward and backward hidden states, passed through a linear layer\n","        encoder_outputs, hidden = self.encoder(src, src_len)\n","                \n","        #first input to the decoder is the <sos> tokens\n","        input = trg[0,:]\n","        \n","        mask = self.create_mask(src)\n","\n","        #mask = [batch size, src len]\n","                \n","        for t in range(1, trg_len):\n","            \n","            #insert input token embedding, previous hidden state, all encoder hidden states \n","            #  and mask\n","            #receive output tensor (predictions) and new hidden state\n","            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n","            \n","            #place predictions in a tensor holding predictions for each token\n","            outputs[t] = output\n","            \n","            #decide if we are going to use teacher forcing or not\n","            teacher_force = random.random() < teacher_forcing_ratio\n","            \n","            #get the highest predicted token from our predictions\n","            top1 = output.argmax(1) \n","            \n","            #if teacher forcing, use actual next token as next input\n","            #if not, use predicted token\n","            input = trg[t] if teacher_force else top1\n","            \n","        return outputs"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pW2KIxhxrMGf"},"source":["# 建立模型和重要參數 請保持和前面訓練時一樣"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ybIY0kKGS_gI","executionInfo":{"status":"ok","timestamp":1622123598892,"user_tz":-480,"elapsed":416,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"618609eb-2f20-4df7-adb0-334e7c5aa477"},"source":["INPUT_DIM = len(SRC.vocab)\n","OUTPUT_DIM = len(TRG.vocab)\n","ENC_EMB_DIM = 256\n","DEC_EMB_DIM = 256\n","ENC_HID_DIM = 128 #256 # 注意 encoder hidden layer 設定 必須為 dec 的一半 \n","DEC_HID_DIM = 256 #512\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n","TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n","\n","LEARNING_RATE = 0.001\n","\n","attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n","enc = RNNEncoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n","dec = RNNDecoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n","model = Seq2SeqATTN(enc, dec, SRC_PAD_IDX, device).to(device)\n","\n","optimizer = optim.Adam(model.parameters(),lr=LEARNING_RATE)\n","criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n","\n","\n","def initial_mdl_weights(m):\n","    for name, param in m.named_parameters():\n","        if 'weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","        else:\n","            nn.init.constant_(param.data, 0)\n","            \n","model.apply(initial_mdl_weights)\n","print (\"模型全部參數量: {:10,d} \".format(sum(p.numel() for p in model.parameters())))\n","model"],"execution_count":18,"outputs":[{"output_type":"stream","text":["模型全部參數量:  8,163,636 \n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["Seq2SeqATTN(\n","  (encoder): RNNEncoder(\n","    (embedding): Embedding(3356, 256)\n","    (rnn): GRU(256, 128, bidirectional=True)\n","    (fc): Linear(in_features=256, out_features=256, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): RNNDecoder(\n","    (attention): Attention()\n","    (embedding): Embedding(6196, 256)\n","    (rnn): GRU(512, 256)\n","    (fc_out): Linear(in_features=768, out_features=6196, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"KOpjxQJmTDYU","executionInfo":{"status":"ok","timestamp":1622123609017,"user_tz":-480,"elapsed":263,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}}},"source":["def train(model, iterator, optimizer, criterion, clip):\n","    \n","    model.train()\n","    \n","    epoch_loss = 0\n","    \n","    for i, batch in enumerate(iterator):\n","        \n","        src, src_len = batch.src\n","        trg = batch.trg\n","        \n","        optimizer.zero_grad()\n","        \n","        output = model(src, src_len.cpu() , trg)\n","        \n","        #trg = [trg len, batch size]\n","        #output = [trg len, batch size, output dim]\n","        \n","        output_dim = output.shape[-1]\n","        \n","        output = output[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","        \n","        #trg = [(trg len - 1) * batch size]\n","        #output = [(trg len - 1) * batch size, output dim]\n","        \n","        loss = criterion(output, trg)\n","        \n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)\n","def evaluate(model, iterator, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(iterator):\n","\n","            src, src_len = batch.src\n","            trg = batch.trg\n","\n","            output = model(src, src_len.cpu(), trg, 0) #turn off teacher forcing\n","            \n","            #trg = [trg len, batch size]\n","            #output = [trg len, batch size, output dim]\n","\n","            output_dim = output.shape[-1]\n","            \n","            output = output[1:].view(-1, output_dim)\n","            trg = trg[1:].view(-1)\n","\n","            #trg = [(trg len - 1) * batch size]\n","            #output = [(trg len - 1) * batch size, output dim]\n","\n","            loss = criterion(output, trg)\n","\n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lFHp7Llj8pmj","executionInfo":{"status":"ok","timestamp":1622123935701,"user_tz":-480,"elapsed":325957,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"26a3e495-7c9b-4e59-805b-7a66c7daea93"},"source":["MAX_EPOCHS = 30\n","CLIP = 1\n","model_dir =  '/content/drive/My Drive/Colab Notebooks/NLP_course/day23/model/'\n","best_valid_loss = 9999999\n","\n","for epoch in range(MAX_EPOCHS):\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n","    valid_loss = evaluate(model, valid_iterator, criterion)\n","    \n","    end_time = time.time()\n","    \n","    # torch.save(model.state_dict(), model_dir + 'model-{}.pt'.format(epoch))\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), model_dir + 'best-model.pt')\n","        print(f'Epoch {epoch}: save best model ')\n","   \n","    print (\"Epoch {} training time: {:.2f} sec Training Loss: {:.3f} , Valiation Loss: {:.3f}\".format( epoch , end_time - start_time , train_loss , valid_loss))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Epoch 0: save best model \n","Epoch 0 training time: 10.87 sec Training Loss: 5.511 , Valiation Loss: 5.045\n","Epoch 1: save best model \n","Epoch 1 training time: 10.85 sec Training Loss: 4.609 , Valiation Loss: 4.779\n","Epoch 2: save best model \n","Epoch 2 training time: 10.86 sec Training Loss: 4.204 , Valiation Loss: 4.621\n","Epoch 3: save best model \n","Epoch 3 training time: 10.82 sec Training Loss: 3.941 , Valiation Loss: 4.424\n","Epoch 4: save best model \n","Epoch 4 training time: 10.76 sec Training Loss: 3.693 , Valiation Loss: 4.246\n","Epoch 5: save best model \n","Epoch 5 training time: 10.80 sec Training Loss: 3.425 , Valiation Loss: 4.133\n","Epoch 6: save best model \n","Epoch 6 training time: 10.77 sec Training Loss: 3.192 , Valiation Loss: 4.055\n","Epoch 7: save best model \n","Epoch 7 training time: 10.72 sec Training Loss: 2.978 , Valiation Loss: 3.957\n","Epoch 8: save best model \n","Epoch 8 training time: 10.81 sec Training Loss: 2.810 , Valiation Loss: 3.869\n","Epoch 9: save best model \n","Epoch 9 training time: 10.90 sec Training Loss: 2.605 , Valiation Loss: 3.856\n","Epoch 10: save best model \n","Epoch 10 training time: 10.86 sec Training Loss: 2.456 , Valiation Loss: 3.793\n","Epoch 11 training time: 10.73 sec Training Loss: 2.289 , Valiation Loss: 3.798\n","Epoch 12: save best model \n","Epoch 12 training time: 10.73 sec Training Loss: 2.201 , Valiation Loss: 3.757\n","Epoch 13: save best model \n","Epoch 13 training time: 10.77 sec Training Loss: 2.058 , Valiation Loss: 3.725\n","Epoch 14: save best model \n","Epoch 14 training time: 10.79 sec Training Loss: 1.974 , Valiation Loss: 3.701\n","Epoch 15: save best model \n","Epoch 15 training time: 10.71 sec Training Loss: 1.867 , Valiation Loss: 3.697\n","Epoch 16: save best model \n","Epoch 16 training time: 10.73 sec Training Loss: 1.771 , Valiation Loss: 3.684\n","Epoch 17 training time: 10.85 sec Training Loss: 1.683 , Valiation Loss: 3.713\n","Epoch 18 training time: 10.79 sec Training Loss: 1.604 , Valiation Loss: 3.718\n","Epoch 19 training time: 10.81 sec Training Loss: 1.551 , Valiation Loss: 3.694\n","Epoch 20 training time: 10.89 sec Training Loss: 1.484 , Valiation Loss: 3.713\n","Epoch 21 training time: 10.83 sec Training Loss: 1.453 , Valiation Loss: 3.709\n","Epoch 22 training time: 10.87 sec Training Loss: 1.375 , Valiation Loss: 3.710\n","Epoch 23 training time: 10.85 sec Training Loss: 1.314 , Valiation Loss: 3.739\n","Epoch 24 training time: 10.86 sec Training Loss: 1.271 , Valiation Loss: 3.756\n","Epoch 25 training time: 10.80 sec Training Loss: 1.241 , Valiation Loss: 3.781\n","Epoch 26 training time: 10.70 sec Training Loss: 1.198 , Valiation Loss: 3.759\n","Epoch 27 training time: 10.80 sec Training Loss: 1.176 , Valiation Loss: 3.796\n","Epoch 28 training time: 10.80 sec Training Loss: 1.118 , Valiation Loss: 3.834\n","Epoch 29 training time: 10.85 sec Training Loss: 1.085 , Valiation Loss: 3.856\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ukg9t_iOTHlG","executionInfo":{"status":"ok","timestamp":1622124895481,"user_tz":-480,"elapsed":732,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"87399f7b-9d89-49ce-d67c-44b3adbfdb97"},"source":["model_dir =  '/content/drive/My Drive/Colab Notebooks/NLP_course/day23/model/'\n","model.load_state_dict(torch.load(model_dir + 'best-model.pt'))\n","#model.load_state_dict(torch.load(model_dir + 'model-7.pt'))\n","test_loss = evaluate(model, test_iterator, criterion)\n","\n","print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["| Test Loss: 3.752 | Test PPL:  42.602 |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q-caE1Y1TL5p","executionInfo":{"status":"ok","timestamp":1622124911590,"user_tz":-480,"elapsed":7,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}}},"source":["def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n","\n","    model.eval()\n","        \n","    #if isinstance(sentence, str):\n","    #    nlp = spacy_en = spacy.load('en_core_web_sm')\n","    #    tokens = [token.text.lower() for token in spacy_en(sentence)]\n","    #else:\n","    #    tokens = [token.lower() for token in sentence]\n","\n","    tokens = [token.lower() for token in sentence]\n","        \n","    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n","        \n","    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n","    \n","    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n","\n","    src_len = torch.LongTensor([len(src_indexes)]).to(device)\n","    \n","    with torch.no_grad():\n","        encoder_outputs, hidden = model.encoder(src_tensor, src_len.cpu())\n","\n","    mask = model.create_mask(src_tensor)\n","        \n","    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n","\n","    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n","    \n","    for i in range(max_len):\n","\n","        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n","                \n","        with torch.no_grad():\n","            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n","\n","        attentions[i] = attention\n","            \n","        pred_token = output.argmax(1).item()\n","        \n","        trg_indexes.append(pred_token)\n","\n","        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n","            break\n","    \n","    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n","    \n","    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTVaH_JGGIkS","executionInfo":{"status":"ok","timestamp":1622125008765,"user_tz":-480,"elapsed":13870,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"f11b1f0c-6cda-4143-893a-81228c7fb113"},"source":["def calculate_bleu(data, src_field, trg_field, model, device, max_len=50):    \n","    trgs, pred_trgs = [], []\n","    for datum in data:\n","        src = vars(datum)['src']\n","        trg = vars(datum)['trg']\n","        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n","        \n","        # cut off <eos> token\n","        pred_trg = pred_trg[:-1]\n","        \n","        pred_trgs.append(pred_trg)\n","        trgs.append([trg])\n","        \n","    return bleu_score(pred_trgs, trgs)\n","    \n","bleu_score = calculate_bleu(test_dataset, SRC, TRG, model, device)\n","print(f'BLEU score = {bleu_score * 100:.2f}')"],"execution_count":26,"outputs":[{"output_type":"stream","text":["BLEU score = 14.96\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lcUnPfomHG6z","executionInfo":{"status":"ok","timestamp":1622125095042,"user_tz":-480,"elapsed":301,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"badd92c8-d2cd-478c-b02a-64aa20a5936a"},"source":["example_idx = 369\n","\n","src = vars(train_dataset.examples[example_idx])['src']\n","print(f'src = {src}')\n","trg = vars(train_dataset.examples[example_idx])['trg']\n","print(f'trg = {trg}')\n","\n","translation, attention = translate_sentence(src, SRC, TRG, model, device)\n","print(f'predicted trg = {translation}')\n"],"execution_count":32,"outputs":[{"output_type":"stream","text":["src = ['我', '想', '講', '一', '口', '流', '利', '的', '英', '語']\n","trg = ['i', 'would', 'like', 'to', 'speak', 'english', 'fluently', '.']\n","predicted trg = ['i', 'want', 'to', 'speak', 'english', 'fluently', '.', '<eos>']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9jhh_5_SYYLT","executionInfo":{"status":"ok","timestamp":1622125113984,"user_tz":-480,"elapsed":308,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}}},"source":["def display_attention(sentence, translation, attention):\n","    \n","    fig = plt.figure(figsize=(10,10))\n","    ax = fig.add_subplot(111)\n","    \n","    attention = attention.squeeze(1).cpu().detach().numpy()\n","    \n","    cax = ax.matshow(attention, cmap='bone')\n","   \n","    #fontdict = {\"fontproperties\": zhfont}\n","    \n","    #ax.set_xticks(range(max(max_len_tar, len(predicted_seq))))\n","    #ax.set_xlim(-0.5, max_len_tar -1.5)\n","    \n","    #ax.set_yticks(range(len(sentence) + 2))\n","    #ax.set_xticklabels([subword_encoder_zh.decode([i]) for i in predicted_seq \n","    #                    if i < subword_encoder_zh.vocab_size], \n","    #                   fontdict=fontdict, fontsize=18)\n","    \n","    #plt.rcParams[\"font.family\"]=\"sans-serif\"\n","    #plt.rcParams['font.sans-serif']=['STSong'] #用来正常显示中文标签\n","    \n","    ax.tick_params(labelsize=15)\n","    ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n","                       rotation=45 , fontproperties=myfont) #, fontdict=fontdict)\n","    ax.set_yticklabels(['']+translation, fontproperties=myfont) # , fontdict=fontdict)\n","\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","    plt.show()\n","    plt.close()"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V4n7915Mrcs1"},"source":["# 作業重點\n","## 請選擇一個好的翻譯結果\n","## 將其 ATTENTION 視覺化 \n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pRYXjqgvYb-E","executionInfo":{"status":"ok","timestamp":1622125124430,"user_tz":-480,"elapsed":488,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"148ff665-a486-40a7-9af1-62e0f276924b"},"source":["# 請在這邊自行調整 sample index \n","# 觀察不同句子的 ATTENTION 結果\n","example_idx = 369\n","\n","src = vars(train_dataset.examples[example_idx])['src']\n","trg = vars(train_dataset.examples[example_idx])['trg']\n","\n","print(f'src = {src}')\n","print(f'trg = {trg}')\n","\n","translation, attention = translate_sentence(src, SRC, TRG, model, device)\n","\n","print(f'predicted trg = {translation}')"],"execution_count":34,"outputs":[{"output_type":"stream","text":["src = ['我', '想', '講', '一', '口', '流', '利', '的', '英', '語']\n","trg = ['i', 'would', 'like', 'to', 'speak', 'english', 'fluently', '.']\n","predicted trg = ['i', 'want', 'to', 'speak', 'english', 'fluently', '.', '<eos>']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2cdlptGJrsfv"},"source":["# 請觀察翻譯文 和被翻譯文的語意對應"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"id":"H8f8csPSYfkU","executionInfo":{"status":"ok","timestamp":1622125130384,"user_tz":-480,"elapsed":270,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"6c102181-c597-48bd-9439-8fca238d5970"},"source":["print (\"\".join(src ))\n","display_attention(src, translation, attention)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["我想講一口流利的英語\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x720 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Ake_IJd2YiG3"},"source":[""],"execution_count":null,"outputs":[]}]}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrWWUhFlUprI"
   },
   "source": [
    "# 作業 : 實作英文-德文翻譯機器人\n",
    "***\n",
    "## [作業目標]\n",
    "\n",
    "用 pytorch 實作一個英文-德文翻譯機器人\n",
    "\n",
    "## [作業目標]\n",
    "\n",
    "*   語言資料處理\n",
    "*   使用 LSTM 建構 Encoder: EncoderLSTM\n",
    "*   使用 LSTM 建構 Decoder: DecoderLSTM\n",
    "*   搭建 Sequence to Sequence 模型: Seq2Seq\n",
    "*   撰寫訓練函式\n",
    "*   撰寫測試函式\n",
    "\n",
    "## [問題]\n",
    "\n",
    "在 Colab 實際上執行完這個範例後，請改用 BiLSTM 來建構 Encoder 與 Decoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgPfcYR26SxF"
   },
   "source": [
    "## 安裝 spacy\n",
    "\n",
    "We'll also make use of spaCy to tokenize our data. To install spaCy, follow the instructions here making sure to install both the English and German models with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 840,
     "status": "ok",
     "timestamp": 1621751338982,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "KZMF-qrP6RKy",
    "outputId": "8366490f-a795-4850-aa54-be55129d46aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 23 06:28:58 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   53C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20991,
     "status": "ok",
     "timestamp": 1621751426698,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "Lzjl5xnFTm6l",
    "outputId": "f6d9df1d-7eca-4c28-bd13-cf6775d6a09c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling spacy-2.2.4:\n",
      "  Successfully uninstalled spacy-2.2.4\n",
      "Collecting spacy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/d8/0361bbaf7a1ff56b44dca04dace54c82d63dad7475b7d25ea1baefafafb2/spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8MB 241kB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (56.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
      "Collecting catalogue<2.1.0,>=2.0.3\n",
      "  Downloading https://files.pythonhosted.org/packages/9c/10/dbc1203a4b1367c7b02fddf08cb2981d9aa3e688d398f587cea0ab9e3bec/catalogue-2.0.4-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
      "Collecting pydantic<1.8.0,>=1.7.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/fa/d43f31874e1f2a9633e4c025be310f2ce7a8350017579e9e837a62630a7e/pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1MB)\n",
      "\u001b[K     |████████████████████████████████| 9.1MB 172kB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/84/dfdfc9f6f04f6b88207d96d9520b911e5fec0c67ff47a0dea31ab5429a1e/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 48.6MB/s \n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.4\n",
      "  Downloading https://files.pythonhosted.org/packages/8d/67/d4002a18e26bf29b17ab563ddb55232b445ab6a02f97bf17d1345ff34d3f/spacy_legacy-3.0.5-py2.py3-none-any.whl\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
      "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
      "Collecting pathy>=0.3.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/87/5991d87be8ed60beb172b4062dbafef18b32fa559635a8e2b633c2974f85/pathy-0.5.2-py3-none-any.whl (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
      "Collecting thinc<8.1.0,>=8.0.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/87/decceba68a0c6ca356ddcb6aea8b2500e71d9bc187f148aae19b747b7d3c/thinc-8.0.3-cp37-cp37m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 49.3MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy) (3.4.1)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Collecting click<7.2.0,>=7.1.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 12.6MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.0)\n",
      "Collecting smart-open<4.0.0,>=2.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 63.2MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for smart-open: filename=smart_open-3.0.0-cp37-none-any.whl size=107098 sha256=567ab676965f612797eb211676558a655ccf7ba4d01d6463543c0c964b3ce563\n",
      "  Stored in directory: /root/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n",
      "Successfully built smart-open\n",
      "Installing collected packages: catalogue, pydantic, srsly, spacy-legacy, click, typer, smart-open, pathy, thinc, spacy\n",
      "  Found existing installation: catalogue 1.0.0\n",
      "    Uninstalling catalogue-1.0.0:\n",
      "      Successfully uninstalled catalogue-1.0.0\n",
      "  Found existing installation: srsly 1.0.5\n",
      "    Uninstalling srsly-1.0.5:\n",
      "      Successfully uninstalled srsly-1.0.5\n",
      "  Found existing installation: click 8.0.0\n",
      "    Uninstalling click-8.0.0:\n",
      "      Successfully uninstalled click-8.0.0\n",
      "  Found existing installation: smart-open 5.0.0\n",
      "    Uninstalling smart-open-5.0.0:\n",
      "      Successfully uninstalled smart-open-5.0.0\n",
      "  Found existing installation: thinc 7.4.0\n",
      "    Uninstalling thinc-7.4.0:\n",
      "      Successfully uninstalled thinc-7.4.0\n",
      "Successfully installed catalogue-2.0.4 click-7.1.2 pathy-0.5.2 pydantic-1.7.4 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.5 srsly-2.4.1 thinc-8.0.3 typer-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall spacy -y\n",
    "!pip install -U spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyd4LijE7vGo"
   },
   "source": [
    "## 引用需要的模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 26820,
     "status": "ok",
     "timestamp": 1621751434314,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "RanKHsWTu-rn"
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.legacy.datasets import Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import random\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from pprint import pprint\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9h9rmgr74Sk"
   },
   "source": [
    "## 下載英文預料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34030,
     "status": "ok",
     "timestamp": 1621751442888,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "XyskUGjGSr-0",
    "outputId": "a718546d-211e-4a8a-e701-39efe9169f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-23 06:30:35.301346: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Collecting en-core-web-sm==3.0.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7MB)\n",
      "\u001b[K     |████████████████████████████████| 13.7MB 224kB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.9)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.5.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (56.1.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.23.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.7.4.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.41.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.4.1)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.0)\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Found existing installation: en-core-web-sm 2.2.5\n",
      "    Uninstalling en-core-web-sm-2.2.5:\n",
      "      Successfully uninstalled en-core-web-sm-2.2.5\n",
      "Successfully installed en-core-web-sm-3.0.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "total 8\n",
      "drwxr-xr-x 2 root root 4096 May 23 06:30 .\n",
      "drwxr-xr-x 3 root root 4096 May 23 06:30 ..\n",
      "total 8\n",
      "drwxr-xr-x 2 root root 4096 May 23 06:30 .\n",
      "drwxr-xr-x 3 root root 4096 May 23 06:30 ..\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./data\n",
    "!mkdir ./data/multi30k\n",
    "!python -m spacy download en\n",
    "!ls ./data/multi30k -al\n",
    "spacy_english = spacy.load(\"en_core_web_sm\")\n",
    "!ls ./data/multi30k -al"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBestLOF8L4w"
   },
   "source": [
    "## 下載德語語料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42250,
     "status": "ok",
     "timestamp": 1621751452146,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "4Hjr_6AXTRoz",
    "outputId": "974a4000-6325-42b6-8159-42dcb2f7aa19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-23 06:30:43.731647: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n",
      "full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n",
      "Collecting de-core-news-sm==3.0.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.0.0/de_core_news_sm-3.0.0-py3-none-any.whl (19.3MB)\n",
      "\u001b[K     |████████████████████████████████| 19.3MB 156kB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from de-core-news-sm==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.7.4.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (8.0.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.11.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (1.19.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (4.41.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.4.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (20.9)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (56.1.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.23.0)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (1.7.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.5.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (1.24.3)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.0.0)\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.0.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n",
      "total 8\n",
      "drwxr-xr-x 2 root root 4096 May 23 06:30 .\n",
      "drwxr-xr-x 3 root root 4096 May 23 06:30 ..\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download de\n",
    "spacy_de = spacy.load(\"de_core_news_sm\")\n",
    "!ls ./data/multi30k -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49076,
     "status": "ok",
     "timestamp": 1621751459415,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "dK984GbYv8Y-",
    "outputId": "b07f3a33-6063-47bd-acf4-45230a8dd41e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'machine', 'learning']\n",
      "downloading training.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:00<00:00, 1.62MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading validation.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 275kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading mmt_task1_test2016.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 267kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in target (en) vocabulary: 4556\n",
      "Unique tokens in source (german) vocabulary: 5374\n"
     ]
    }
   ],
   "source": [
    "def tokenize_de(text):\n",
    "  return [token.text for token in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_english(text):\n",
    "  return [token.text for token in spacy_english.tokenizer(text)]\n",
    "\n",
    "### Sample Run ###\n",
    "\n",
    "sample_text = \"I love machine learning\"\n",
    "print(tokenize_english(sample_text))\n",
    "\n",
    "german = Field(tokenize=tokenize_de, lower=True,\n",
    "               init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "english = Field(tokenize=tokenize_english, lower=True,\n",
    "               init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "#translate sentence from english to german\n",
    "train_data, valid_data, test_data = Multi30k.splits(exts = (\".en\", \".de\"),\n",
    "                                                    fields=(english, german))\n",
    "\n",
    "english.build_vocab(train_data, max_size=10000, min_freq=3)\n",
    "german.build_vocab(train_data, max_size=10000, min_freq=3)\n",
    "\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(english.vocab)}\")\n",
    "print(f\"Unique tokens in source (german) vocabulary: {len(german.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 48607,
     "status": "ok",
     "timestamp": 1621751459416,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "sZ3fiLno60K_"
   },
   "outputs": [],
   "source": [
    "# word_2_idx = dict(e[2])\n",
    "# idx_2_word = {}\n",
    "# for k,v in word_2_idx.items():\n",
    "#   idx_2_word[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48118,
     "status": "ok",
     "timestamp": 1621751459417,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "WunTmSIJzBaC",
    "outputId": "392978e2-5b58-4c23-8870-b7b91803061f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 29000\n",
      "Number of validation examples: 1014\n",
      "Number of testing examples: 1000\n",
      "dict_keys(['src', 'trg'])\n",
      "dict_values([['a', 'man', 'in', 'green', 'holds', 'a', 'guitar', 'while', 'the', 'other', 'man', 'observes', 'his', 'shirt', '.'], ['ein', 'mann', 'in', 'grün', 'hält', 'eine', 'gitarre', ',', 'während', 'der', 'andere', 'mann', 'sein', 'hemd', 'ansieht', '.']])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")\n",
    "\n",
    "print(train_data[5].__dict__.keys())\n",
    "pprint(train_data[5].__dict__.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 47656,
     "status": "ok",
     "timestamp": 1621751459417,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "zRGP9EsizRRN"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data), \n",
    "                                                                      batch_size = BATCH_SIZE, \n",
    "                                                                      sort_within_batch=True,\n",
    "                                                                      sort_key=lambda x: len(x.src),\n",
    "                                                                      device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47221,
     "status": "ok",
     "timestamp": 1621751459418,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "E3nozOT8zdeD",
    "outputId": "b5817ef8-190b-404e-a1e7-05b772c85b02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English -  two young , white males are outside near many bushes .  Length -  11\n",
      "German -  zwei junge weiße männer sind im freien in der nähe vieler büsche .  Length -  13\n",
      "\n",
      "English -  several men in hard hats are operating a giant pulley system .  Length -  12\n",
      "German -  mehrere männer mit schutzhelmen bedienen ein antriebsradsystem .  Length -  8\n",
      "\n",
      "English -  a little girl climbing into a wooden playhouse .  Length -  9\n",
      "German -  ein kleines mädchen klettert in ein spielhaus aus holz .  Length -  10\n",
      "\n",
      "English -  a man in a blue shirt is standing on a ladder cleaning a window .  Length -  15\n",
      "German -  ein mann in einem blauen hemd steht auf einer leiter und putzt ein fenster .  Length -  15\n",
      "\n",
      "English -  two men are at the stove preparing food .  Length -  9\n",
      "German -  zwei männer stehen am herd und bereiten essen zu .  Length -  10\n",
      "\n",
      "English -  a man in green holds a guitar while the other man observes his shirt .  Length -  15\n",
      "German -  ein mann in grün hält eine gitarre , während der andere mann sein hemd ansieht .  Length -  16\n",
      "\n",
      "English -  a man is smiling at a stuffed lion  Length -  8\n",
      "German -  ein mann lächelt einen ausgestopften löwen an .  Length -  8\n",
      "\n",
      "English -  a trendy girl talking on her cellphone while gliding slowly down the street .  Length -  14\n",
      "German -  ein schickes mädchen spricht mit dem handy während sie langsam die straße entlangschwebt .  Length -  14\n",
      "\n",
      "English -  a woman with a large purse is walking by a gate .  Length -  12\n",
      "German -  eine frau mit einer großen geldbörse geht an einem tor vorbei .  Length -  12\n",
      "\n",
      "English -  boys dancing on poles in the middle of the night .  Length -  11\n",
      "German -  jungen tanzen mitten in der nacht auf pfosten .  Length -  9\n",
      "\n",
      "Maximum Length of English sentence 44 and German sentence 41 in the dataset\n",
      "Minimum Length of English sentence 1 and German sentence 4 in the dataset\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "max_len_eng = []\n",
    "max_len_ger = []\n",
    "for data in train_data:\n",
    "  max_len_ger.append(len(data.src))\n",
    "  max_len_eng.append(len(data.trg))\n",
    "  if count < 10 :\n",
    "    print(\"English - \",*data.src, \" Length - \", len(data.src))\n",
    "    print(\"German - \",*data.trg, \" Length - \", len(data.trg))\n",
    "    print()\n",
    "  count += 1\n",
    "\n",
    "print(\"Maximum Length of English sentence {} and German sentence {} in the dataset\".format(max(max_len_eng),max(max_len_ger)))\n",
    "print(\"Minimum Length of English sentence {} and German sentence {} in the dataset\".format(min(max_len_eng),min(max_len_ger)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58023,
     "status": "ok",
     "timestamp": 1621751470611,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "pE_S5yMdwRsT",
    "outputId": "72c6a5d8-b55a-4125-d1c4-2cb5338a147e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes torch.Size([15, 32]) torch.Size([22, 32])\n",
      "\n",
      "English -  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0') tensor([   4,   21,    7,    4,    4,    4,   16,  113,    4,    4,    4,    4,\n",
      "           4,    4,    7,    4,    4,    4,    4,    4,    7,    4,    4,    4,\n",
      "           4,    4,    4,   13,    4,    4, 2691,    4], device='cuda:0') tensor([  35,  233,  348,  178,   14,  120,   30,  326,    9,   33,   38,   39,\n",
      "         224,   24,   34,   14,   55,    9,   53,    9,   33,   38,  183,   64,\n",
      "         120,    9,   55, 1890,    9,    9,  304,   35], device='cuda:0') tensor([1027,    9,   10,   42,    6,    6,   17,   22,   11,    6,   12,  406,\n",
      "         105,    9,  189, 2617,   10,    6,   34,   11,    6,   12,   13,    6,\n",
      "          22,   10,    6, 2017,   10,   11,    4,   89], device='cuda:0') tensor([   8,   10,    6,  210,  148,   21,   36,   62,    4,    4,   19,   13,\n",
      "         558,    6,   10,   49,   22,    4,   10,    4,    7,   19,    4,    4,\n",
      "           4,   73,   86,   15, 3097,   16,  331,    8], device='cuda:0') tensor([  27,  130,    7,   33,  411,   86,    8,  628,   14,  194,    8,  519,\n",
      "          18,    4,   41,    4,    4,   31,  230,   14,  278,  359,   26, 1918,\n",
      "          52,    6,   10,   48,    8,   50,  184,    7], device='cuda:0') tensor([ 182,   18,   47,   36,    4,  117,    7,   11,   17,   23,    4,  492,\n",
      "         497,   61,   10,   59,  311,   23,    8,    6,   31,  129,  501,   13,\n",
      "         317,  362,    8, 4511,    4,   17,   13,   88], device='cuda:0') tensor([  80, 1098,   45,    6,  503,  241,  578,  703, 2514,  140,  444,   42,\n",
      "           4,   81,   22, 3535,   67,   10,    7,  279,  300,   20,   11,    4,\n",
      "          10,  294,    4,   73, 4318,  280,    0,   13], device='cuda:0') tensor([   4, 1075,    8,   43,   68,    4,   12,  468,  182,    4,   49,   25,\n",
      "         677,  940,  132,  211,   11,   32, 2171,   80,   10,  305,    4,  327,\n",
      "         407,   13, 2670, 2909,    6,    4,   12,    4], device='cuda:0') tensor([  55,   18,   18,   12,   40,  281,    4,   17,  790,    0,    4,   15,\n",
      "          28,    4,  148,  842,  190,   49, 1401,    4,    0,   57,  234,  422,\n",
      "        1187,    4,  347, 1827,   43,    0, 1211,   59], device='cuda:0') tensor([ 218,   21,    4,    4,    4,   20,  404,   25,    8,   18,  101,   31,\n",
      "          27,  917,   11,    8,   20,  512,   20, 1082,  171,    4,   78, 1018,\n",
      "           8,  234,    6,  111,   12,   45,    6,  166], device='cuda:0') tensor([   4,  233, 1083,  186,  503,    7,  434,   47,    7,   44, 2668,   11,\n",
      "        1240,  131,  549,    7,    4,   54,    4,   12,    7,  291,   44,   18,\n",
      "           4,   11,    7,   42,    4, 2146,    7,   93], device='cuda:0') tensor([ 277,   14, 1214,  200,  641,  988,  520, 2057,  425,  203,  522,  182,\n",
      "        3972,  271,   23,   88, 2130, 1038,  435,  391,  288,   77,   99,  143,\n",
      "        4390,    0,  563,  149,   77, 1102,   98,  143], device='cuda:0') tensor([   5,    5,    5,    5,    5,    5,    5,    5,    5,    5, 1110,    5,\n",
      "           5,    5,    5,    5,    5,    5,    5,    5,    5,    5,    5,    5,\n",
      "           5,    5,    5,    5,    5,    5,    5,    5], device='cuda:0') tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')  Length -  15\n",
      "\n",
      "German -  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0') tensor([ 5,  5,  5,  5,  8,  8, 18, 76,  5,  5,  8,  8,  5,  5, 15,  8,  5,  5,\n",
      "         5,  5, 39,  8,  8,  8,  8,  5,  5, 11,  5,  5,  0,  5],\n",
      "       device='cuda:0') tensor([  32,  130,   49, 3183,   16,   16,   30,  330,   13,   25,   36,  638,\n",
      "         550,   96,   26,   16,   49,   13,   70,   13,   25,  113,  709,   67,\n",
      "         165,   13,   49,    0,   13,   13, 3220,   32], device='cuda:0') tensor([156,  13,  48,  25,   7,   7,  52,  11,  10,   7,  22,   9, 844,  13,\n",
      "         83,  60,  61,   7,  26,  10,  20,   9,  67,  11,  11,   7,   7, 347,\n",
      "        108,  10,  23,  29], device='cuda:0') tensor([  12,   48,   20,   29,  313,    6,   12,  102,    8,    6,   41,   21,\n",
      "         193,    7,    7,   21,   19,    6,  217,    8, 3813,   17,   11,    6,\n",
      "         380,   15,  555, 1584,   21,   18,   21,   55], device='cuda:0') tensor([  24,  147,   63,   27,  198,  405,   24,  827,   16,  257,   12,   15,\n",
      "         994,   14,  203,   14,    0,   50,   12,   16,  475,   23,  226, 1463,\n",
      "         250,   97,   12,   43,    6,   45,    6,   91], device='cuda:0') tensor([317,   9,  10,  14,   9, 128, 455,  10, 489,  79,   6, 253,  56, 153,\n",
      "        219,  78,  10,  40,   6,  11,  69, 444, 477,   9, 542,  44,   6,   0,\n",
      "          0,   9, 487,  11], device='cuda:0') tensor([  47,   14,   37, 2676,   17,   68,   44, 1572,  822,   37, 1801,    9,\n",
      "           9,   89,   10, 3412,  238,   31,  433,  524,   42,   27,   10,   21,\n",
      "        1882,  544,    0,  196,   27,   52,  200,    6], device='cuda:0') tensor([   6,  628,   23, 2161,    8,   12,  382,  167,   12,   23,    7,  349,\n",
      "          35,  303,   11,   44,    7,   47,   12,   47,   33,    6,  201,   24,\n",
      "          12,   10,    7,    0,    6,    7,    9,   78], device='cuda:0') tensor([  49,   16,   21,    4, 1274,    6,    0,    0,    6,    5,   14,   10,\n",
      "         132,   19,  355,    0,    6,  593,   39,   14,  190, 2461,   62,    8,\n",
      "           5,   11,   33,   22,  104,    6,   35,  214], device='cuda:0') tensor([   9, 1375,   14,    3,   12, 4192,    4,    4,  440,    0,  152,  243,\n",
      "        1538, 2815,  265,   55, 2350,    9, 1344,  319,    4, 5350,  259,  967,\n",
      "        4005,  201,  609,   15,    0, 4635,   20,   98], device='cuda:0') tensor([  39,   28, 4068,    1,    8,    8,    3,    3,    4,    0,   74,  352,\n",
      "        5256,    4,    4,   91,    4,   39,    4,    4,    3,   93,    4,  471,\n",
      "           4,   10,    4,  136,    4,   10,   86,  176], device='cuda:0') tensor([   5,  695,  420,    1, 1220, 1326,    1,    1,    3,   21,   21, 2635,\n",
      "           4,    3,    3,  117,    3,   28,    3,    3,    1,    4,    3, 1913,\n",
      "           3,  275,    3,  378,    3,  187,    8,    4], device='cuda:0') tensor([ 286,    4,    4,    1,  228,    4,    1,    1,    1,   33, 2266,    4,\n",
      "           3,    1,    1,    4,    1,  695,    1,    1,    1,    3,    1,   48,\n",
      "           1,    4,    1,    4,    1,    0,    0,    3], device='cuda:0') tensor([ 184,    3,    3,    1,    4,    3,    1,    1,    1,  467, 4185,    3,\n",
      "           1,    1,    1,    3,    1,   48,    1,    1,    1,    1,    1,    4,\n",
      "           1,    3,    1,    3,    1,    4,   21,    1], device='cuda:0') tensor([   4,    1,    1,    1,    3,    1,    1,    1,    1,    4, 2503,    1,\n",
      "           1,    1,    1,    1,    1,    4,    1,    1,    1,    1,    1,    3,\n",
      "           1,    1,    1,    1,    1,    3,   33,    1], device='cuda:0') tensor([   3,    1,    1,    1,    1,    1,    1,    1,    1,    3,    4,    1,\n",
      "           1,    1,    1,    1,    1,    3,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1, 5105,    1], device='cuda:0') tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  3,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 28,  1],\n",
      "       device='cuda:0') tensor([  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1, 144,   1], device='cuda:0') tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 48,  1],\n",
      "       device='cuda:0') tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 4, 1], device='cuda:0') tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 3, 1], device='cuda:0')  Length -  22\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for data in train_iterator:\n",
    "  if count < 1 :\n",
    "    print(\"Shapes\", data.src.shape, data.trg.shape)\n",
    "    print()\n",
    "    print(\"English - \",*data.src, \" Length - \", len(data.src))\n",
    "    print()\n",
    "    print(\"German - \",*data.trg, \" Length - \", len(data.trg))\n",
    "    temp_ger = data.src\n",
    "    temp_eng = data.trg\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 57578,
     "status": "ok",
     "timestamp": 1621751470611,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "xSP5RchXyuaz"
   },
   "outputs": [],
   "source": [
    "temp_eng_idx = (temp_eng).cpu().detach().numpy()\n",
    "temp_ger_idx = (temp_ger).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "executionInfo": {
     "elapsed": 57579,
     "status": "ok",
     "timestamp": 1621751471039,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "tgAmQS4I6k9v",
    "outputId": "2f818406-a7ae-40f7-d1d0-a9f2fe5e2b25"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S_1</th>\n",
       "      <th>S_2</th>\n",
       "      <th>S_3</th>\n",
       "      <th>S_4</th>\n",
       "      <th>S_5</th>\n",
       "      <th>S_6</th>\n",
       "      <th>S_7</th>\n",
       "      <th>S_8</th>\n",
       "      <th>S_9</th>\n",
       "      <th>S_10</th>\n",
       "      <th>S_11</th>\n",
       "      <th>S_12</th>\n",
       "      <th>S_13</th>\n",
       "      <th>S_14</th>\n",
       "      <th>S_15</th>\n",
       "      <th>S_16</th>\n",
       "      <th>S_17</th>\n",
       "      <th>S_18</th>\n",
       "      <th>S_19</th>\n",
       "      <th>S_20</th>\n",
       "      <th>S_21</th>\n",
       "      <th>S_22</th>\n",
       "      <th>S_23</th>\n",
       "      <th>S_24</th>\n",
       "      <th>S_25</th>\n",
       "      <th>S_26</th>\n",
       "      <th>S_27</th>\n",
       "      <th>S_28</th>\n",
       "      <th>S_29</th>\n",
       "      <th>S_30</th>\n",
       "      <th>S_31</th>\n",
       "      <th>S_32</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time Steps</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>130</td>\n",
       "      <td>49</td>\n",
       "      <td>3183</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>330</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>638</td>\n",
       "      <td>550</td>\n",
       "      <td>96</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>49</td>\n",
       "      <td>13</td>\n",
       "      <td>70</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>113</td>\n",
       "      <td>709</td>\n",
       "      <td>67</td>\n",
       "      <td>165</td>\n",
       "      <td>13</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>3220</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>844</td>\n",
       "      <td>13</td>\n",
       "      <td>83</td>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>347</td>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>313</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>102</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>21</td>\n",
       "      <td>193</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>217</td>\n",
       "      <td>8</td>\n",
       "      <td>3813</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>380</td>\n",
       "      <td>15</td>\n",
       "      <td>555</td>\n",
       "      <td>1584</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>147</td>\n",
       "      <td>63</td>\n",
       "      <td>27</td>\n",
       "      <td>198</td>\n",
       "      <td>405</td>\n",
       "      <td>24</td>\n",
       "      <td>827</td>\n",
       "      <td>16</td>\n",
       "      <td>257</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>994</td>\n",
       "      <td>14</td>\n",
       "      <td>203</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>475</td>\n",
       "      <td>23</td>\n",
       "      <td>226</td>\n",
       "      <td>1463</td>\n",
       "      <td>250</td>\n",
       "      <td>97</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>317</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>128</td>\n",
       "      <td>455</td>\n",
       "      <td>10</td>\n",
       "      <td>489</td>\n",
       "      <td>79</td>\n",
       "      <td>6</td>\n",
       "      <td>253</td>\n",
       "      <td>56</td>\n",
       "      <td>153</td>\n",
       "      <td>219</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>69</td>\n",
       "      <td>444</td>\n",
       "      <td>477</td>\n",
       "      <td>9</td>\n",
       "      <td>542</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>487</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>2676</td>\n",
       "      <td>17</td>\n",
       "      <td>68</td>\n",
       "      <td>44</td>\n",
       "      <td>1572</td>\n",
       "      <td>822</td>\n",
       "      <td>37</td>\n",
       "      <td>1801</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>10</td>\n",
       "      <td>3412</td>\n",
       "      <td>238</td>\n",
       "      <td>31</td>\n",
       "      <td>433</td>\n",
       "      <td>524</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>1882</td>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>27</td>\n",
       "      <td>52</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>628</td>\n",
       "      <td>23</td>\n",
       "      <td>2161</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>382</td>\n",
       "      <td>167</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>349</td>\n",
       "      <td>35</td>\n",
       "      <td>303</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>47</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>201</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>1274</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>132</td>\n",
       "      <td>19</td>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>593</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>190</td>\n",
       "      <td>2461</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>104</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>1375</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4192</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>440</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>243</td>\n",
       "      <td>1538</td>\n",
       "      <td>2815</td>\n",
       "      <td>265</td>\n",
       "      <td>55</td>\n",
       "      <td>2350</td>\n",
       "      <td>9</td>\n",
       "      <td>1344</td>\n",
       "      <td>319</td>\n",
       "      <td>4</td>\n",
       "      <td>5350</td>\n",
       "      <td>259</td>\n",
       "      <td>967</td>\n",
       "      <td>4005</td>\n",
       "      <td>201</td>\n",
       "      <td>609</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4635</td>\n",
       "      <td>20</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>39</td>\n",
       "      <td>28</td>\n",
       "      <td>4068</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>352</td>\n",
       "      <td>5256</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "      <td>471</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>86</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>695</td>\n",
       "      <td>420</td>\n",
       "      <td>1</td>\n",
       "      <td>1220</td>\n",
       "      <td>1326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>2635</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1913</td>\n",
       "      <td>3</td>\n",
       "      <td>275</td>\n",
       "      <td>3</td>\n",
       "      <td>378</td>\n",
       "      <td>3</td>\n",
       "      <td>187</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>286</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>228</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>2266</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>695</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>467</td>\n",
       "      <td>4185</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2503</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            S_1   S_2   S_3   S_4   S_5  ...  S_28  S_29  S_30  S_31  S_32\n",
       "Time Steps                               ...                              \n",
       "1             2     2     2     2     2  ...     2     2     2     2     2\n",
       "2             5     5     5     5     8  ...    11     5     5     0     5\n",
       "3            32   130    49  3183    16  ...     0    13    13  3220    32\n",
       "4           156    13    48    25     7  ...   347   108    10    23    29\n",
       "5            12    48    20    29   313  ...  1584    21    18    21    55\n",
       "6            24   147    63    27   198  ...    43     6    45     6    91\n",
       "7           317     9    10    14     9  ...     0     0     9   487    11\n",
       "8            47    14    37  2676    17  ...   196    27    52   200     6\n",
       "9             6   628    23  2161     8  ...     0     6     7     9    78\n",
       "10           49    16    21     4  1274  ...    22   104     6    35   214\n",
       "11            9  1375    14     3    12  ...    15     0  4635    20    98\n",
       "12           39    28  4068     1     8  ...   136     4    10    86   176\n",
       "13            5   695   420     1  1220  ...   378     3   187     8     4\n",
       "14          286     4     4     1   228  ...     4     1     0     0     3\n",
       "15          184     3     3     1     4  ...     3     1     4    21     1\n",
       "16            4     1     1     1     3  ...     1     1     3    33     1\n",
       "17            3     1     1     1     1  ...     1     1     1  5105     1\n",
       "18            1     1     1     1     1  ...     1     1     1    28     1\n",
       "19            1     1     1     1     1  ...     1     1     1   144     1\n",
       "20            1     1     1     1     1  ...     1     1     1    48     1\n",
       "21            1     1     1     1     1  ...     1     1     1     4     1\n",
       "22            1     1     1     1     1  ...     1     1     1     3     1\n",
       "\n",
       "[22 rows x 32 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng_idx = pd.DataFrame(data = temp_eng_idx, columns = [str(\"S_\")+str(x) for x in np.arange(1, 33)])\n",
    "df_eng_idx.index.name = 'Time Steps'\n",
    "df_eng_idx.index = df_eng_idx.index + 1 \n",
    "# df_eng_idx.to_csv('/content/idx.csv')\n",
    "df_eng_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "executionInfo": {
     "elapsed": 57160,
     "status": "ok",
     "timestamp": 1621751471040,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "vXy1431M6o02",
    "outputId": "c1abc4bc-49bc-4845-cee5-8a0e7fb00676"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S_1</th>\n",
       "      <th>S_2</th>\n",
       "      <th>S_3</th>\n",
       "      <th>S_4</th>\n",
       "      <th>S_5</th>\n",
       "      <th>S_6</th>\n",
       "      <th>S_7</th>\n",
       "      <th>S_8</th>\n",
       "      <th>S_9</th>\n",
       "      <th>S_10</th>\n",
       "      <th>S_11</th>\n",
       "      <th>S_12</th>\n",
       "      <th>S_13</th>\n",
       "      <th>S_14</th>\n",
       "      <th>S_15</th>\n",
       "      <th>S_16</th>\n",
       "      <th>S_17</th>\n",
       "      <th>S_18</th>\n",
       "      <th>S_19</th>\n",
       "      <th>S_20</th>\n",
       "      <th>S_21</th>\n",
       "      <th>S_22</th>\n",
       "      <th>S_23</th>\n",
       "      <th>S_24</th>\n",
       "      <th>S_25</th>\n",
       "      <th>S_26</th>\n",
       "      <th>S_27</th>\n",
       "      <th>S_28</th>\n",
       "      <th>S_29</th>\n",
       "      <th>S_30</th>\n",
       "      <th>S_31</th>\n",
       "      <th>S_32</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time Steps</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "      <td>&lt;sos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>to</td>\n",
       "      <td>over</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>,</td>\n",
       "      <td>on</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>street</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>and</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sitting</td>\n",
       "      <td>working</td>\n",
       "      <td>by</td>\n",
       "      <td>shack</td>\n",
       "      <td>two</td>\n",
       "      <td>two</td>\n",
       "      <td>men</td>\n",
       "      <td>dance</td>\n",
       "      <td>with</td>\n",
       "      <td>white</td>\n",
       "      <td>standing</td>\n",
       "      <td>match</td>\n",
       "      <td>rocky</td>\n",
       "      <td>grass</td>\n",
       "      <td>black</td>\n",
       "      <td>two</td>\n",
       "      <td>by</td>\n",
       "      <td>with</td>\n",
       "      <td>small</td>\n",
       "      <td>with</td>\n",
       "      <td>white</td>\n",
       "      <td>several</td>\n",
       "      <td>urban</td>\n",
       "      <td>hat</td>\n",
       "      <td>taking</td>\n",
       "      <td>with</td>\n",
       "      <td>by</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "      <td>suburban</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>side</td>\n",
       "      <td>with</td>\n",
       "      <td>three</td>\n",
       "      <td>white</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>green</td>\n",
       "      <td>and</td>\n",
       "      <td>is</td>\n",
       "      <td>the</td>\n",
       "      <td>wearing</td>\n",
       "      <td>man</td>\n",
       "      <td>splashing</td>\n",
       "      <td>with</td>\n",
       "      <td>around</td>\n",
       "      <td>through</td>\n",
       "      <td>brown</td>\n",
       "      <td>the</td>\n",
       "      <td>black</td>\n",
       "      <td>is</td>\n",
       "      <td>at</td>\n",
       "      <td>man</td>\n",
       "      <td>hat</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>board</td>\n",
       "      <td>wall</td>\n",
       "      <td>is</td>\n",
       "      <td>shirt</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>of</td>\n",
       "      <td>three</td>\n",
       "      <td>at</td>\n",
       "      <td>blue</td>\n",
       "      <td>she</td>\n",
       "      <td>in</td>\n",
       "      <td>of</td>\n",
       "      <td>'s</td>\n",
       "      <td>on</td>\n",
       "      <td>in</td>\n",
       "      <td>walking</td>\n",
       "      <td>an</td>\n",
       "      <td>coat</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>an</td>\n",
       "      <td>people</td>\n",
       "      <td>in</td>\n",
       "      <td>sunglasses</td>\n",
       "      <td>on</td>\n",
       "      <td>12</td>\n",
       "      <td>are</td>\n",
       "      <td>and</td>\n",
       "      <td>in</td>\n",
       "      <td>does</td>\n",
       "      <td>,</td>\n",
       "      <td>jackets</td>\n",
       "      <td>raising</td>\n",
       "      <td>an</td>\n",
       "      <td>to</td>\n",
       "      <td>an</td>\n",
       "      <td>child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>young</td>\n",
       "      <td>pants</td>\n",
       "      <td>children</td>\n",
       "      <td>his</td>\n",
       "      <td>horse</td>\n",
       "      <td>both</td>\n",
       "      <td>young</td>\n",
       "      <td>cold</td>\n",
       "      <td>two</td>\n",
       "      <td>getting</td>\n",
       "      <td>of</td>\n",
       "      <td>,</td>\n",
       "      <td>kayak</td>\n",
       "      <td>woman</td>\n",
       "      <td>mouth</td>\n",
       "      <td>woman</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>women</td>\n",
       "      <td>of</td>\n",
       "      <td>two</td>\n",
       "      <td>pulling</td>\n",
       "      <td>shirt</td>\n",
       "      <td>during</td>\n",
       "      <td>approaching</td>\n",
       "      <td>trees</td>\n",
       "      <td>hair</td>\n",
       "      <td>of</td>\n",
       "      <td>front</td>\n",
       "      <td>in</td>\n",
       "      <td>holding</td>\n",
       "      <td>in</td>\n",
       "      <td>sits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sweater</td>\n",
       "      <td>man</td>\n",
       "      <td>is</td>\n",
       "      <td>woman</td>\n",
       "      <td>man</td>\n",
       "      <td>play</td>\n",
       "      <td>reads</td>\n",
       "      <td>is</td>\n",
       "      <td>showing</td>\n",
       "      <td>running</td>\n",
       "      <td>in</td>\n",
       "      <td>outdoor</td>\n",
       "      <td>looking</td>\n",
       "      <td>baby</td>\n",
       "      <td>clothing</td>\n",
       "      <td>riding</td>\n",
       "      <td>is</td>\n",
       "      <td>down</td>\n",
       "      <td>in</td>\n",
       "      <td>and</td>\n",
       "      <td>into</td>\n",
       "      <td>dock</td>\n",
       "      <td>appears</td>\n",
       "      <td>man</td>\n",
       "      <td>eyes</td>\n",
       "      <td>her</td>\n",
       "      <td>in</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>man</td>\n",
       "      <td>instrument</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>water</td>\n",
       "      <td>woman</td>\n",
       "      <td>playing</td>\n",
       "      <td>broad</td>\n",
       "      <td>are</td>\n",
       "      <td>ball</td>\n",
       "      <td>her</td>\n",
       "      <td>observing</td>\n",
       "      <td>sleeps</td>\n",
       "      <td>playing</td>\n",
       "      <td>newly</td>\n",
       "      <td>man</td>\n",
       "      <td>man</td>\n",
       "      <td>stands</td>\n",
       "      <td>is</td>\n",
       "      <td>exposed</td>\n",
       "      <td>train</td>\n",
       "      <td>red</td>\n",
       "      <td>aged</td>\n",
       "      <td>gentleman</td>\n",
       "      <td>-</td>\n",
       "      <td>his</td>\n",
       "      <td>is</td>\n",
       "      <td>an</td>\n",
       "      <td>drawn</td>\n",
       "      <td>hit</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>kids</td>\n",
       "      <td>his</td>\n",
       "      <td>green</td>\n",
       "      <td>band</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in</td>\n",
       "      <td>helmets</td>\n",
       "      <td>shirt</td>\n",
       "      <td>interesting</td>\n",
       "      <td>on</td>\n",
       "      <td>of</td>\n",
       "      <td>machine</td>\n",
       "      <td>each</td>\n",
       "      <td>of</td>\n",
       "      <td>shirt</td>\n",
       "      <td>the</td>\n",
       "      <td>phone</td>\n",
       "      <td>dog</td>\n",
       "      <td>body</td>\n",
       "      <td>and</td>\n",
       "      <td>her</td>\n",
       "      <td>the</td>\n",
       "      <td>water</td>\n",
       "      <td>of</td>\n",
       "      <td>water</td>\n",
       "      <td>girl</td>\n",
       "      <td>in</td>\n",
       "      <td>watch</td>\n",
       "      <td>young</td>\n",
       "      <td>of</td>\n",
       "      <td>is</td>\n",
       "      <td>the</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>man</td>\n",
       "      <td>riding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>by</td>\n",
       "      <td>two</td>\n",
       "      <td>an</td>\n",
       "      <td>a</td>\n",
       "      <td>groups</td>\n",
       "      <td>in</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>in</td>\n",
       "      <td>.</td>\n",
       "      <td>woman</td>\n",
       "      <td>is</td>\n",
       "      <td>gray</td>\n",
       "      <td>people</td>\n",
       "      <td>family</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>in</td>\n",
       "      <td>empty</td>\n",
       "      <td>street</td>\n",
       "      <td>woman</td>\n",
       "      <td>eating</td>\n",
       "      <td>cotton</td>\n",
       "      <td>yellow</td>\n",
       "      <td>on</td>\n",
       "      <td>.</td>\n",
       "      <td>and</td>\n",
       "      <td>girl</td>\n",
       "      <td>wearing</td>\n",
       "      <td>girls</td>\n",
       "      <td>in</td>\n",
       "      <td>dog</td>\n",
       "      <td>look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>man</td>\n",
       "      <td>hospital</td>\n",
       "      <td>woman</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>of</td>\n",
       "      <td>maneuvers</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>woods</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>walk</td>\n",
       "      <td>chair</td>\n",
       "      <td>branch</td>\n",
       "      <td>propped</td>\n",
       "      <td>bag</td>\n",
       "      <td>child</td>\n",
       "      <td>pay</td>\n",
       "      <td>man</td>\n",
       "      <td>shoot</td>\n",
       "      <td>trick</td>\n",
       "      <td>a</td>\n",
       "      <td>5350</td>\n",
       "      <td>floor</td>\n",
       "      <td>turn</td>\n",
       "      <td>earring</td>\n",
       "      <td>watch</td>\n",
       "      <td>pointing</td>\n",
       "      <td>,</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>4635</td>\n",
       "      <td>at</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>street</td>\n",
       "      <td>while</td>\n",
       "      <td>france</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>a</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>some</td>\n",
       "      <td>gear</td>\n",
       "      <td>5256</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>sits</td>\n",
       "      <td>a</td>\n",
       "      <td>street</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>behind</td>\n",
       "      <td>a</td>\n",
       "      <td>cream</td>\n",
       "      <td>a</td>\n",
       "      <td>is</td>\n",
       "      <td>a</td>\n",
       "      <td>has</td>\n",
       "      <td>a</td>\n",
       "      <td>is</td>\n",
       "      <td>orange</td>\n",
       "      <td>there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>.</td>\n",
       "      <td>place</td>\n",
       "      <td>public</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>barbecue</td>\n",
       "      <td>horseback</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>an</td>\n",
       "      <td>an</td>\n",
       "      <td>were</td>\n",
       "      <td>a</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>dress</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>while</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>a</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>motorized</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>market</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>steps</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>room</td>\n",
       "      <td>on</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cellphone</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>workers</td>\n",
       "      <td>a</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>girl</td>\n",
       "      <td>candle</td>\n",
       "      <td>a</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>a</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>place</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>three</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>a</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>a</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>day</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>a</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>rider</td>\n",
       "      <td>lollipop</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>three</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>a</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>a</td>\n",
       "      <td>an</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>a</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>a</td>\n",
       "      <td>frying</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>a</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>girl</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>a</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>5105</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>while</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>bench</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>three</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>a</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;eos&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  S_1       S_2       S_3  ...     S_30        S_31        S_32\n",
       "Time Steps                                 ...                                 \n",
       "1               <sos>     <sos>     <sos>  ...    <sos>       <sos>       <sos>\n",
       "2                   .         .         .  ...        .       <unk>           .\n",
       "3             sitting   working        by  ...     with    suburban     sitting\n",
       "4                side      with     three  ...       is       shirt        blue\n",
       "5                  of     three        at  ...       to          an       child\n",
       "6               young     pants  children  ...  holding          in        sits\n",
       "7             sweater       man        is  ...      man  instrument         and\n",
       "8               water     woman   playing  ...    green        band          in\n",
       "9                  in   helmets     shirt  ...      the         man      riding\n",
       "10                 by       two        an  ...       in         dog        look\n",
       "11                man  hospital     woman  ...     4635          at  background\n",
       "12             street     while    france  ...       is      orange       there\n",
       "13                  .     place    public  ...     room          on           a\n",
       "14          cellphone         a         a  ...    <unk>       <unk>       <eos>\n",
       "15                day     <eos>     <eos>  ...        a          an       <pad>\n",
       "16                  a     <pad>     <pad>  ...    <eos>        girl       <pad>\n",
       "17              <eos>     <pad>     <pad>  ...    <pad>        5105       <pad>\n",
       "18              <pad>     <pad>     <pad>  ...    <pad>       while       <pad>\n",
       "19              <pad>     <pad>     <pad>  ...    <pad>       bench       <pad>\n",
       "20              <pad>     <pad>     <pad>  ...    <pad>       three       <pad>\n",
       "21              <pad>     <pad>     <pad>  ...    <pad>           a       <pad>\n",
       "22              <pad>     <pad>     <pad>  ...    <pad>       <eos>       <pad>\n",
       "\n",
       "[22 rows x 32 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_2_word = {idx: word for idx, word in enumerate(english.vocab.itos)}\n",
    "df_eng_word = pd.DataFrame(columns = [str(\"S_\")+str(x) for x in np.arange(1, 33)])\n",
    "df_eng_word = df_eng_idx.replace(idx_2_word)\n",
    "# df_eng_word.to_csv('/content/Words.csv')\n",
    "df_eng_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLV-t-MzVQdg"
   },
   "source": [
    "## 用 LSTM 搭建的 Encoder 類別: EncoderLSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56146,
     "status": "ok",
     "timestamp": 1621751471297,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "0dZT3Zs17yMQ",
    "outputId": "ae23cfa6-927c-4596-cb0e-ad64cec255ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderLSTM(\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (embedding): Embedding(4556, 300)\n",
      "  (biLSTM): LSTM(300, 1024, num_layers=2, dropout=0.5, bidirectional=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "    super(EncoderLSTM, self).__init__()\n",
    "\n",
    "    # Size of the one hot vectors that will be the input to the encoder\n",
    "    #self.input_size = input_size\n",
    "\n",
    "    # Output size of the word embedding NN\n",
    "    #self.embedding_size = embedding_size\n",
    "\n",
    "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    # Number of layers in the lstm\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    # Regularization parameter\n",
    "    self.dropout = nn.Dropout(p)\n",
    "    self.tag = True\n",
    "\n",
    "    # Shape --------------------> (4556 , 300) [input size(english vocab), embedding dims]\n",
    "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "    \n",
    "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
    "    # self.LSTM = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = p)\n",
    "    self.biLSTM = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = p, bidirectional=True)\n",
    "\n",
    "  # Shape of x (26, 32) [Sequence_length, batch_size]\n",
    "  def forward(self, x):\n",
    "\n",
    "    # Shape -----------> (26, 32, 300) [Sequence_length , batch_size , embedding dims]\n",
    "    embedding = self.dropout(self.embedding(x))\n",
    "    \n",
    "    # Shape --> outputs (26, 32, 1024) [Sequence_length , batch_size , hidden_size]\n",
    "    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size]\n",
    "    # outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n",
    "    outputs, (hidden_state, cell_state) = self.biLSTM(embedding)\n",
    "    hidden_state = hidden_state.view(self.num_layers, -1, self.hidden_size * 2) #use biLSTM --> hidden size *2\n",
    "    cell_state = cell_state.view(self.num_layers, -1, self.hidden_size * 2) #use biLSTM --> hidden size *2\n",
    "\n",
    "    return hidden_state, cell_state\n",
    "\n",
    "input_size_encoder = len(english.vocab)\n",
    "encoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "\n",
    "encoder_lstm = EncoderLSTM(input_size_encoder, encoder_embedding_size,\n",
    "                           hidden_size, num_layers, encoder_dropout).to(device)\n",
    "print(encoder_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTew1tbHVer5"
   },
   "source": [
    "## 用 LSTM 搭建的 decoder 類別: DecoderLSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55506,
     "status": "ok",
     "timestamp": 1621751472104,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "wPGbQiBP72iX",
    "outputId": "21e21747-ae59-4557-dfb5-89695f2b9f2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderLSTM(\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (embedding): Embedding(5374, 300)\n",
      "  (LSTM): LSTM(300, 2048, num_layers=2, dropout=0.5)\n",
      "  (fc): Linear(in_features=2048, out_features=5374, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, output_size):\n",
    "    super(DecoderLSTM, self).__init__()\n",
    "\n",
    "    # Size of the one hot vectors that will be the input to the encoder\n",
    "    #self.input_size = input_size\n",
    "\n",
    "    # Output size of the word embedding NN\n",
    "    #self.embedding_size = embedding_size\n",
    "\n",
    "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    # Number of layers in the lstm\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    # Size of the one hot vectors that will be the output from the decoder (german Vocab Size)\n",
    "    self.output_size = output_size\n",
    "\n",
    "    # Regularization parameter\n",
    "    self.dropout = nn.Dropout(p)\n",
    "\n",
    "    # Shape --------------------> (4556, 300) [input size(english vocab size), embedding dims]\n",
    "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "\n",
    "    # Shape -----------> (300, 2, 1024*2) [embedding dims, hidden size, num layers]\n",
    "    self.LSTM = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = p)\n",
    "\n",
    "    # Shape -----------> (1024*2, 5374) [hidden size, output size(german vocab size)]\n",
    "    self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "  # Shape of x (32) [batch_size]\n",
    "  def forward(self, x, hidden_state, cell_state):\n",
    "\n",
    "    # Shape of x (1, 32) [1, batch_size]\n",
    "    x = x.unsqueeze(0)\n",
    "\n",
    "    # Shape -----------> (1, 32, 300) [1, batch_size, embedding dims]\n",
    "    embedding = self.dropout(self.embedding(x))\n",
    "\n",
    "    # Shape --> outputs (1, 32, 1024*2) [1, batch_size , hidden_size]\n",
    "    # Shape --> (hs, cs) (2, 32, 1024*2) , (2, 32, 1024*2) [num_layers, batch_size size, hidden_size] (passing encoder's hs, cs - context vectors)\n",
    "    outputs, (hidden_state, cell_state) = self.LSTM(embedding, (hidden_state, cell_state))\n",
    "\n",
    "    # Shape --> predictions (1, 32, 5374) [ 1, batch_size , output_size(german vocab size)]\n",
    "    predictions = self.fc(outputs)\n",
    "\n",
    "    # Shape --> predictions (32, 5374) [batch_size , output_size(german vocab size)]\n",
    "    predictions = predictions.squeeze(0)\n",
    "\n",
    "    return predictions, hidden_state, cell_state\n",
    "\n",
    "input_size_decoder = len(german.vocab)\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024 * 2\n",
    "num_layers = 2\n",
    "decoder_dropout = 0.5\n",
    "output_size = len(german.vocab)\n",
    "\n",
    "decoder_lstm = DecoderLSTM(input_size_decoder, decoder_embedding_size,\n",
    "                           hidden_size, num_layers, decoder_dropout, output_size).to(device)\n",
    "print(decoder_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54860,
     "status": "ok",
     "timestamp": 1621751472105,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "xof3dPly753w",
    "outputId": "d13292ef-6523-4728-9772-467e405743ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 32])\n",
      "torch.Size([23, 32])\n",
      "tensor([  8,   5,   5,  76,  15,   5,  76,   5,   5,  76,   5,   8,   8,   8,\n",
      "         99,   8,   5,  18,   8,  43,   5,   8, 389,   7,   5,  18,  14,   5,\n",
      "          5,   5,   5,   5], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "  print(batch.src.shape)\n",
    "  print(batch.trg.shape)\n",
    "  break\n",
    "\n",
    "x = batch.trg[1]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGnQbCnGVire"
   },
   "source": [
    "# Sequence to Sequence 類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 53444,
     "status": "ok",
     "timestamp": 1621751472105,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "_vzOor_Q782h"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "  def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
    "    super(Seq2Seq, self).__init__()\n",
    "    self.Encoder_LSTM = Encoder_LSTM\n",
    "    self.Decoder_LSTM = Decoder_LSTM\n",
    "\n",
    "  def forward(self, source, target, tfr=0.5):\n",
    "    # Shape - Source : (10, 32) [(Sentence length english + some padding), Number of Sentences]\n",
    "    batch_size = source.shape[1]\n",
    "\n",
    "    # Shape - Source : (14, 32) [(Sentence length german + some padding), Number of Sentences]\n",
    "    target_len = target.shape[0]\n",
    "    target_vocab_size = len(german.vocab)\n",
    "    \n",
    "    # Shape --> outputs (14, 32, 5374) 5374:german vocab size\n",
    "    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "\n",
    "    # Shape --> (hs, cs) (2, 32, 1024) ,(2, 32, 1024) [num_layers, batch_size size, hidden_size] (contains encoder's hs, cs - context vectors)\n",
    "    hidden_state, cell_state = self.Encoder_LSTM(source)\n",
    "\n",
    "    # Shape of x (32 elements)\n",
    "    x = target[0] # Trigger token <SOS>\n",
    "\n",
    "    for i in range(1, target_len):\n",
    "      # Shape --> output (32, 5374) 5374:german vocab size\n",
    "      output, hidden_state, cell_state = self.Decoder_LSTM(x, hidden_state, cell_state)\n",
    "      outputs[i] = output\n",
    "      best_guess = output.argmax(1) # 0th dimension is batch size, 1st dimension is word embedding\n",
    "      x = target[i] if random.random() < tfr else best_guess # Either pass the next word correctly from the dataset or use the earlier predicted word\n",
    "\n",
    "    # Shape --> outputs (14, 32, 5374) \n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 52916,
     "status": "ok",
     "timestamp": 1621751472106,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "ywW6f9fM8AMa"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "learning_rate = 0.001\n",
    "writer = SummaryWriter(f\"runs/loss_plot\")\n",
    "step = 0\n",
    "\n",
    "model = Seq2Seq(encoder_lstm, decoder_lstm).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49992,
     "status": "ok",
     "timestamp": 1621751472106,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "IkSQARTIb13o",
    "outputId": "10371f2b-9137-48b8-a90e-75a8e88f7b67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (Encoder_LSTM): EncoderLSTM(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(4556, 300)\n",
       "    (biLSTM): LSTM(300, 1024, num_layers=2, dropout=0.5, bidirectional=True)\n",
       "  )\n",
       "  (Decoder_LSTM): DecoderLSTM(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(5374, 300)\n",
       "    (LSTM): LSTM(300, 2048, num_layers=2, dropout=0.5)\n",
       "    (fc): Linear(in_features=2048, out_features=5374, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 48291,
     "status": "ok",
     "timestamp": 1621751472107,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "fQyZ_vfq8G6C"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
    "    spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    if type(sentence) == str:\n",
    "        tokens = [token.text.lower() for token in spacy_eng(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "    tokens.insert(0, english.init_token)\n",
    "    tokens.append(english.eos_token)\n",
    "    text_to_indices = [english.vocab.stoi[token] for token in tokens]\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    # Build encoder hidden, cell state\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.Encoder_LSTM(sentence_tensor)\n",
    "\n",
    "    outputs = [german.vocab.stoi[\"<sos>\"]]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.Decoder_LSTM(previous_word, hidden, cell)\n",
    "            best_guess = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        # Model predicts it's the end of the sentence\n",
    "        if output.argmax(1).item() == german.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [german.vocab.itos[idx] for idx in outputs]\n",
    "    return translated_sentence[1:]\n",
    "\n",
    "# 用來評估模型的函式: bleu\n",
    "def bleu(data, model, german, english, device):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "\n",
    "    for example in data:\n",
    "        src = vars(example)[\"src\"]\n",
    "        trg = vars(example)[\"trg\"]\n",
    "\n",
    "        prediction = translate_sentence(model, src, german, english, device)\n",
    "        prediction = prediction[:-1]  # remove <eos> token\n",
    "\n",
    "        targets.append([trg])\n",
    "        outputs.append(prediction)\n",
    "\n",
    "    return bleu_score(outputs, targets)\n",
    "\n",
    "def checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss):\n",
    "    print('saving')\n",
    "    print()\n",
    "    state = {'model': model,'best_loss': best_loss,'epoch': epoch,'rng_state': torch.get_rng_state(), 'optimizer': optimizer.state_dict(),}\n",
    "    torch.save(state, './checkpoint-NMT')\n",
    "    torch.save(model.state_dict(),'./checkpoint-NMT-SD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11787463,
     "status": "ok",
     "timestamp": 1621763259578,
     "user": {
      "displayName": "王博正",
      "photoUrl": "",
      "userId": "01330688402941364671"
     },
     "user_tz": -480
    },
    "id": "ysc4A5HX8Qyg",
    "outputId": "f012e6bf-6210-42f3-813d-aaaa0db83ff4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 / 50\n",
      "Translated example sentence 1: \n",
      " ['jüngeres', 'entgegen', 'gruppenfoto', 'gruppenfoto', 'übergibt', 'übergibt', 'rast', 'ziehen', 'lachen', 'lachen', 'turnschuhe', 'lachen', 'turnschuhe', 'stöcken', 'herzen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen', 'rostigen']\n",
      "saving\n",
      "\n",
      "Epoch_Loss - 4.623289108276367\n",
      "\n",
      "Epoch - 2 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 4.101475715637207\n",
      "\n",
      "Epoch - 3 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', '<unk>', '<unk>', 'einem', '<unk>', 'auf', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.6764230728149414\n",
      "\n",
      "Epoch - 4 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'auf', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.9601850509643555\n",
      "\n",
      "Epoch - 5 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'auf', 'einem', '.', '<eos>']\n",
      "Epoch_Loss - 3.813727378845215\n",
      "\n",
      "Epoch - 6 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', '<unk>', 'und', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 4.167057037353516\n",
      "\n",
      "Epoch - 7 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'in', 'einem', '<unk>', ',', 'der', '.', '<eos>']\n",
      "Epoch_Loss - 3.992936134338379\n",
      "\n",
      "Epoch - 8 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'auf', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 4.1001176834106445\n",
      "\n",
      "Epoch - 9 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'einem', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.6598918437957764\n",
      "\n",
      "Epoch - 10 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'mit', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 4.22374963760376\n",
      "\n",
      "Epoch - 11 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'auf', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.576498031616211\n",
      "\n",
      "Epoch - 12 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'auf', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 4.0197834968566895\n",
      "\n",
      "Epoch - 13 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'mit', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.7211344242095947\n",
      "\n",
      "Epoch - 14 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'mit', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.281118869781494\n",
      "\n",
      "Epoch - 15 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'mit', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.006911039352417\n",
      "\n",
      "Epoch - 16 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'mit', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.0538177490234375\n",
      "\n",
      "Epoch - 17 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', '<unk>', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.4664127826690674\n",
      "\n",
      "Epoch - 18 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', '<unk>', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.4309449195861816\n",
      "\n",
      "Epoch - 19 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'mit', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.339107036590576\n",
      "\n",
      "Epoch - 20 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 4.161723613739014\n",
      "\n",
      "Epoch - 21 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', '<unk>', 'und', '<unk>', '<unk>', '<unk>', '.', '.', '<eos>']\n",
      "Epoch_Loss - 3.9131386280059814\n",
      "\n",
      "Epoch - 22 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', '<unk>', 'und', '<unk>', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.565948486328125\n",
      "\n",
      "Epoch - 23 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'auf', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.0052120685577393\n",
      "\n",
      "Epoch - 24 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'auf', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 2.71349835395813\n",
      "\n",
      "Epoch - 25 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', '<unk>', 'und', 'auf', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.5740554332733154\n",
      "\n",
      "Epoch - 26 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'mit', 'einem', 'und', 'einem', 'grauen', 'hemd', 'spielt', 'auf', 'einem', '.', '<eos>']\n",
      "Epoch_Loss - 2.6441218852996826\n",
      "\n",
      "Epoch - 27 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', '<unk>', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.530994415283203\n",
      "\n",
      "Epoch - 28 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'auf', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.0619707107543945\n",
      "\n",
      "Epoch - 29 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'auf', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 2.7781410217285156\n",
      "\n",
      "Epoch - 30 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'auf', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.100052833557129\n",
      "\n",
      "Epoch - 31 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'mit', 'einem', '<unk>', 'hemd', 'und', 'auf', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.5036239624023438\n",
      "\n",
      "Epoch - 32 / 50\n",
      "Translated example sentence 1: \n",
      " ['zwei', 'männer', 'in', 'auf', 'einem', '<unk>', 'in', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.5352165699005127\n",
      "\n",
      "Epoch - 33 / 50\n",
      "Translated example sentence 1: \n",
      " ['cheerleaders', 'in', 'einem', '<unk>', 'servieren', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.786027669906616\n",
      "\n",
      "Epoch - 34 / 50\n",
      "Translated example sentence 1: \n",
      " ['hunderte', 'von', 'leuten', 'feiern', 'in', 'schlauchbooten', ',', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.6602609157562256\n",
      "\n",
      "Epoch - 35 / 50\n",
      "Translated example sentence 1: \n",
      " ['angestellte', 'in', 'einem', '<unk>', '<unk>', ',', 'der', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.396789312362671\n",
      "\n",
      "Epoch - 36 / 50\n",
      "Translated example sentence 1: \n",
      " ['angestellte', 'in', 'einem', '<unk>', 'in', 'einer', '<unk>', 'und', 'einer', 'zeremonie', '.', '<eos>']\n",
      "Epoch_Loss - 2.5242056846618652\n",
      "\n",
      "Epoch - 37 / 50\n",
      "Translated example sentence 1: \n",
      " ['angestellte', 'in', 'einem', 'medizinischen', 'einrichtung', 'und', 'wählen', 'speisen', 'und', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 2.865917444229126\n",
      "\n",
      "Epoch - 38 / 50\n",
      "Translated example sentence 1: \n",
      " ['angestellte', 'in', 'einem', 'medizinischen', 'einrichtung', 'und', 'wählen', 'speisen', 'und', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.0873711109161377\n",
      "\n",
      "Epoch - 39 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', 'hemd', 'und', 'auf', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 4.182083606719971\n",
      "\n",
      "Epoch - 40 / 50\n",
      "Translated example sentence 1: \n",
      " ['kid', 'in', 'gestreiftem', 'hemd', 'fährt', 'mit', 'fahrrad', 'auf', 'einem', 'motorrad', '.', '<eos>']\n",
      "Epoch_Loss - 3.3514719009399414\n",
      "\n",
      "Epoch - 41 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'mit', 'einem', '<unk>', ',', 'der', 'auf', 'einem', '<unk>', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.2231738567352295\n",
      "\n",
      "Epoch - 42 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', '<unk>', 'und', '<unk>', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 2.847479820251465\n",
      "\n",
      "Epoch - 43 / 50\n",
      "Translated example sentence 1: \n",
      " ['diese', 'frau', 'trägt', 'ein', 'rotes', 't-shirt', 'und', 'stimmt', 'ihr', 'baby', '.', '<eos>']\n",
      "Epoch_Loss - 4.280332565307617\n",
      "\n",
      "Epoch - 44 / 50\n",
      "Translated example sentence 1: \n",
      " ['cheerleaders', 'und', '<unk>', 'gegenseitig', 'in', 'einer', 'japanischen', '<unk>', 'unterlagen', '.', '<eos>']\n",
      "Epoch_Loss - 3.278731107711792\n",
      "\n",
      "Epoch - 45 / 50\n",
      "Translated example sentence 1: \n",
      " ['grundschulkinder', 'in', 'auf', 'einem', 'aussichtspunkt', 'und', 'warten', 'auf', 'den', 'zug', '.', '<eos>']\n",
      "Epoch_Loss - 2.641545057296753\n",
      "\n",
      "Epoch - 46 / 50\n",
      "Translated example sentence 1: \n",
      " ['grundschulkinder', 'in', 'auf', 'einem', '<unk>', 'und', 'warten', 'auf', 'ihre', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 2.452406167984009\n",
      "\n",
      "Epoch - 47 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'mit', 'einem', '<unk>', ',', 'der', 'auf', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 3.736905574798584\n",
      "\n",
      "Epoch - 48 / 50\n",
      "Translated example sentence 1: \n",
      " ['wartungsarbeiter', '<unk>', 'in', 'einem', 'lenkt', 'und', 'warten', 'auf', 'einen', 'zug', '.', '<eos>']\n",
      "Epoch_Loss - 3.4063327312469482\n",
      "\n",
      "Epoch - 49 / 50\n",
      "Translated example sentence 1: \n",
      " ['ein', 'mann', 'in', 'einem', 'einem', '<unk>', 'und', 'einem', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 2.851667881011963\n",
      "\n",
      "Epoch - 50 / 50\n",
      "Translated example sentence 1: \n",
      " ['wartungsarbeiter', 'bieten', 'einen', 'riesigen', 'weihnachtsbaum', ',', 'der', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
      "Epoch_Loss - 2.7653956413269043\n",
      "\n",
      "169.1222018573881\n"
     ]
    }
   ],
   "source": [
    "epoch_loss = 0.0\n",
    "# num_epochs = 100\n",
    "num_epochs = 50\n",
    "best_loss = 999999\n",
    "best_epoch = -1\n",
    "sentence1 = \"a trendy girl talking on her cellphone while gliding slowly down the street .\"\n",
    "ts1  = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n",
    "  model.eval()\n",
    "  translated_sentence1 = translate_sentence(model, sentence1, german, english, device, max_length=50)\n",
    "  print(f\"Translated example sentence 1: \\n {translated_sentence1}\")\n",
    "  ts1.append(translated_sentence1)\n",
    "\n",
    "  model.train(True)\n",
    "  for batch_idx, batch in enumerate(train_iterator):\n",
    "    input = batch.src.to(device)\n",
    "    target = batch.trg.to(device)\n",
    "\n",
    "    # Pass the input and target for model's forward method\n",
    "    output = model(input, target)\n",
    "    output = output[1:].reshape(-1, output.shape[2])\n",
    "    target = target[1:].reshape(-1)\n",
    "\n",
    "    # Clear the accumulating gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Calculate the loss value for every epoch\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    # Calculate the gradients for weights & biases using back-propagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip the gradient value is it exceeds > 1\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "    # Update the weights values using the gradients we calculated using bp \n",
    "    optimizer.step()\n",
    "    step += 1\n",
    "    epoch_loss += loss.item()\n",
    "    writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "\n",
    "  if epoch_loss < best_loss:\n",
    "    best_loss = epoch_loss\n",
    "    best_epoch = epoch\n",
    "    checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss) \n",
    "    if ((epoch - best_epoch) >= 10):\n",
    "      print(\"no improvement in 10 epochs, break\")\n",
    "      break\n",
    "  print(\"Epoch_Loss - {}\".format(loss.item()))\n",
    "  print()\n",
    "  \n",
    "print(epoch_loss / len(train_iterator))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCpms_QeNxeW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "day22.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

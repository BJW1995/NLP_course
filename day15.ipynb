{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"day15.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"O5Pf_RxOIAYv"},"source":["### 作業目的: 透過實作加速版word2vec Skip-gram模型來更加了解高速版的word2vec\n","\n","本次作業會採用Penn Tree Bank資料及，學員可以在ptb.train.txt中取得訓練文本資料。這次作業可以讓學員練習到以pytorch搭建模型與進行文本資料的前處理\n","\n","PS: 建議學員使用Colab (或可以使用GPU加速的機器)來進行作業，不然訓練會訓練到天荒地老....."]},{"cell_type":"markdown","metadata":{"id":"QKKpFV6GJwhs"},"source":["### Import Necessary Libraries"]},{"cell_type":"code","metadata":{"id":"Yjz-fWmbJRPB"},"source":["import os\n","import re\n","import tqdm\n","import random\n","import math\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import urllib.request\n","from typing import List\n","from collections import Counter\n","import torch\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i9xrgPu3KBgJ","executionInfo":{"status":"ok","timestamp":1619951658144,"user_tz":-480,"elapsed":1169,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"da4d04e1-c689-489d-c017-5c8c6e27f746"},"source":["# 讀取資料\n","\n","# Penn Tree Back dataset\n","with open(\"ptb.train.txt\", encoding='utf-8') as f:\n","    lines = f.readlines()\n","    \n","print(f\"Total {len(lines)} lines\")\n","raw_dataset = [line.split() for line in lines]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total 42068 lines\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oAcF_5CQKH_J","executionInfo":{"status":"ok","timestamp":1619951662569,"user_tz":-480,"elapsed":1031,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"5f04d6d7-71a9-4936-fdc7-3b954f11e00a"},"source":["# 查看前5筆\n","raw_dataset[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['aer',\n","  'banknote',\n","  'berlitz',\n","  'calloway',\n","  'centrust',\n","  'cluett',\n","  'fromstein',\n","  'gitano',\n","  'guterman',\n","  'hydro-quebec',\n","  'ipo',\n","  'kia',\n","  'memotec',\n","  'mlx',\n","  'nahb',\n","  'punts',\n","  'rake',\n","  'regatta',\n","  'rubens',\n","  'sim',\n","  'snack-food',\n","  'ssangyong',\n","  'swapo',\n","  'wachter'],\n"," ['pierre',\n","  '<unk>',\n","  'N',\n","  'years',\n","  'old',\n","  'will',\n","  'join',\n","  'the',\n","  'board',\n","  'as',\n","  'a',\n","  'nonexecutive',\n","  'director',\n","  'nov.',\n","  'N'],\n"," ['mr.',\n","  '<unk>',\n","  'is',\n","  'chairman',\n","  'of',\n","  '<unk>',\n","  'n.v.',\n","  'the',\n","  'dutch',\n","  'publishing',\n","  'group'],\n"," ['rudolph',\n","  '<unk>',\n","  'N',\n","  'years',\n","  'old',\n","  'and',\n","  'former',\n","  'chairman',\n","  'of',\n","  'consolidated',\n","  'gold',\n","  'fields',\n","  'plc',\n","  'was',\n","  'named',\n","  'a',\n","  'nonexecutive',\n","  'director',\n","  'of',\n","  'this',\n","  'british',\n","  'industrial',\n","  'conglomerate'],\n"," ['a',\n","  'form',\n","  'of',\n","  'asbestos',\n","  'once',\n","  'used',\n","  'to',\n","  'make',\n","  'kent',\n","  'cigarette',\n","  'filters',\n","  'has',\n","  'caused',\n","  'a',\n","  'high',\n","  'percentage',\n","  'of',\n","  'cancer',\n","  'deaths',\n","  'among',\n","  'a',\n","  'group',\n","  'of',\n","  'workers',\n","  'exposed',\n","  'to',\n","  'it',\n","  'more',\n","  'than',\n","  'N',\n","  'years',\n","  'ago',\n","  'researchers',\n","  'reported']]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3oki6AxhJyj4","executionInfo":{"status":"ok","timestamp":1619951673441,"user_tz":-480,"elapsed":7134,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"5dd8e581-3ebe-4de3-9562-b4a83d913925"},"source":["# 定義資料前處理函示\n","class PreProcessor():\n","    '''Function to do preprocess of input corpus\n","    Parameters\n","    -----------\n","    corpus: str\n","        input corpus to be processed\n","    only_word: bool\n","        whether to filter out non-word\n","    min_freq: int\n","        minimum frequency of a word to be kept\n","    do_subsampling: bool\n","        whether to do subsampling\n","    '''\n","    \n","    def __init__(self, only_word: bool=False, min_freq: int=5, do_subsampling: bool=True, t: float=1e-5):\n","        self.only_word = only_word\n","        self.min_freq = min_freq\n","        self.do_subsampling = do_subsampling\n","        self.t = t\n","    \n","    def process(self, corpus: List[str]):\n","        \n","        word_dic = set()\n","        counter = Counter()\n","        processed_sentence = []\n","        \n","        for rows in corpus:\n","            for sentence in rows:\n","                #將所有字詞轉為小寫\n","                sentence = sentence.lower()\n","                #移除標點符號(可以依據使用狀況決定是否要移除標點符號)\n","                if self.only_word:\n","                    sentence = [word for word in re.findall(r\"[a-zA-Z]*\", sentence) if word != \"\"]\n","                else:\n","                    punctuation_list = ['.', ',', '!', '?']\n","                    for pun in punctuation_list:\n","                        sentence = sentence.replace(pun, ' '+pun)\n","                    sentence = sentence.split(' ')\n","        \n","                #計算字詞頻率\n","                counter.update(sentence)\n","                processed_sentence.append(sentence)\n","    \n","        # hint: 移除頻率過小的字詞 建立word2idx與idx2word與word_frequency辭典\n","        word_cnt = dict(filter(lambda x: x[1] > self.min_freq, counter.items()))\n","        #添加字詞到字典中\n","        self.word2idx = {word: idx for idx, word in enumerate(word_cnt.keys(), 0)}\n","        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n","        self.word_frequency = word_cnt.copy()\n","        \n","        #將文本轉為ID型式與移除文本中頻率過小的文字\n","        self.processed_corpus = [[self.word2idx[word] for word in line if word in self.word2idx] for line in processed_sentence]\n","        self.total_num_words = sum([len(line) for line in self.processed_corpus])\n","        print(f\"Before subsampling: {self.total_num_words} words\")\n","        \n","        # 進行二次採樣(subsampling)\n","        if self.do_subsampling:\n","            self.processed_corpus = [[idx for idx in line if self.subsampling(idx)] for line in self.processed_corpus]\n","            self.total_num_words = sum([len(line) for line in self.processed_corpus])\n","            counter = Counter([self.idx2word[idx] for line in self.processed_corpus for idx in line])\n","            word_cnt = dict(counter.items())\n","            self.word_frequency = word_cnt.copy()\n","            print(f\"After subsampling: {self.total_num_words} words\")\n","        \n","        # hint: 移除空字串\n","        self.processed_corpus = [[idx for idx in line] for line in self.processed_corpus if len(line) != 0]\n","        \n","        return self.processed_corpus, self.word2idx, self.idx2word, self.word_frequency, self.total_num_words\n","    \n","    def subsampling(self, idx):\n","        \n","        p = self.t / self.word_frequency[self.idx2word[idx]] * self.total_num_words\n","        p_w = math.sqrt(p) + p\n","        \n","        return random.uniform(0, 1) < p_w\n","\n","\n","# 進行資料前處理\n","# 這邊我們subsampling的t取1e-4\n","pre_processor = PreProcessor(True, 5, True, 1e-4)\n","corpus, word2idx, idx2word, word2freq, total_num_words = pre_processor.process(raw_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Before subsampling: 888326 words\n","After subsampling: 434815 words\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MfDuJuT5Kkvl"},"source":["### 定義Skip-gram使用的Dataset與collate function"]},{"cell_type":"code","metadata":{"id":"DraniEYMKfWl","executionInfo":{"status":"ok","timestamp":1619954107773,"user_tz":-480,"elapsed":949,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}}},"source":["# 客製化Dataset\n","class SkipGramGetAllDataset(Dataset):\n","    \n","    def __init__(self, corpus, word2freq, word2idx, idx2word, window_size, num_negatives):\n","        self.corpus = corpus\n","        self.word2freq = word2freq\n","        self.word2idx = word2idx\n","        self.idx2word = idx2word\n","        self.window_size = window_size\n","        self.num_negatives = num_negatives\n","        \n","        self.all_targets, self.all_contexts = self._get_all_contexts_targets()\n","        self.all_negatives = self._get_all_negatives()\n","        \n","    def __len__(self):\n","        return len(self.all_targets)\n","    \n","    def __getitem__(self, idx):\n","        \n","        # 返回 目標字詞，上下文，負採樣樣本\n","        return (self.all_targets[idx], self.all_contexts[idx], self.all_negatives[idx])\n","    \n","    def _get_all_contexts_targets(self):\n","        all_targets = []\n","        all_contexts = []\n","        \n","        for line in self.corpus:\n","            if len(line) < 2*self.window_size + 1:\n","                continue\n","            \n","            # 要創建上下文 (考慮window_size)\n","            all_targets += [line[self.window_size:-self.window_size]]\n","            \n","            for index in range(self.window_size, len(line) - self.window_size):\n","                # 創建目標字詞\n","                indices = list(range(max(0, index - self.window_size), min(len(line), index + self.window_size + 1)))\n","                indices.remove(index)\n","                all_contexts.append([line[idx] for idx in indices])\n","                               \n","        return all_targets, all_contexts\n","                               \n","    \n","    def _get_all_negatives(self):\n","        \n","        # 進行負採樣\n","        \n","        cur_exists_words = list(self.word2freq.keys())\n","        sampling_weights = [self.word2freq[word]**0.75 for word in self.word2freq]\n","        population = list(range(len(sampling_weights)))\n","        \n","        all_negatives = []\n","        neg_candidate = []\n","        i = 0\n","        for targets in self.all_targets:\n","            negatives = []\n","            while len(negatives) < self.num_negatives:\n","                if i == len(neg_candidate):\n","                    neg_candidate = random.choices(population, sampling_weights, k=int(1e5))\n","                    neg_candidate = list(map(lambda x: self.word2idx[cur_exists_words[x]], neg_candidate))\n","                    i = 0\n","                if neg_candidate[i] != targets[0]:\n","                    negatives.append(neg_candidate[i])\n","                i += 1\n","            all_negatives.append(negatives)           \n","        \n","        return all_negatives\n","    \n","# 客製化collate_fn\n","def skipgram_collate(data):\n","    contexts = []\n","    target_negative = []\n","    labels = []\n","    for target, context, negative in data:\n","        # 將目標字詞、上下文與負採樣樣本個別打包\n","        target_negative += [target + negative]\n","        labels += [[1] * len(target) + [0] * len(negative)]\n","        contexts += [context]\n","    \n","    return torch.tensor(contexts), torch.tensor(target_negative), torch.tensor(labels)"],"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s94kJ0lKKzG5"},"source":["### 定義Skip-gram模型"]},{"cell_type":"code","metadata":{"id":"kyyQyLxcKpv1","executionInfo":{"status":"ok","timestamp":1619955068613,"user_tz":-480,"elapsed":1627,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}}},"source":["class SkipGram(nn.Module):\n","    \n","    def __init__(self, vocab_size, embed_size):\n","        super(SkipGram, self).__init__()\n","        \n","        self.in_embedding = nn.Embedding(vocab_size, embed_size)\n","        self.out_embedding = nn.Embedding(vocab_size, embed_size)\n","        \n","    def forward(self, contexts, targets):\n","        v = self.in_embedding(contexts)\n","        u = self.out_embedding(targets)\n","        \n","        # do dot product to get output\n","        pred = torch.matmul(v[:,None,:], u.permute(0,2,1))\n","        \n","        return pred.squeeze(dim=1)"],"execution_count":62,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LHZIFz7yK5An"},"source":["### 訓練"]},{"cell_type":"code","metadata":{"id":"Hr4sVBd8K10T","executionInfo":{"status":"ok","timestamp":1619954759744,"user_tz":-480,"elapsed":904,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}}},"source":["# Define hyperparameters\n","\n","use_cuda = torch.cuda.is_available()\n","verbose = True\n","num_epochs = 100\n","batch_size = 512\n","embed_size = 100\n","lr = 0.01\n","\n","model = SkipGram(len(word2idx), embed_size)\n","if use_cuda:\n","    model.cuda()\n","    \n","criterion = nn.BCEWithLogitsLoss(reduction='mean')\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","dataset = SkipGramGetAllDataset(corpus, word2freq, word2idx, idx2word, 1, 5)\n","loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=skipgram_collate)"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a1_gRVMTtFA3","executionInfo":{"status":"ok","timestamp":1619954153557,"user_tz":-480,"elapsed":890,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"6b4c53c5-710a-4a13-c5ee-53e0dc6b5389"},"source":["dataset = SkipGramGetAllDataset(corpus, word2freq, word2idx, idx2word, 1, 5)\n","dataset.__getitem__(0)"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([9], [274, 3128], [1280, 2433, 5252, 829, 8912])"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"sE28LW2_LB0I","executionInfo":{"status":"error","timestamp":1619955199388,"user_tz":-480,"elapsed":1018,"user":{"displayName":"王博正","photoUrl":"","userId":"01330688402941364671"}},"outputId":"efc77b92-d6ea-4911-cb59-b37881cc5f65"},"source":["# Start training\n","\n","lst_loss = []\n","model.train()\n","for epc in tqdm.tqdm(range(num_epochs)):\n","    batch_loss = 0\n","\n","    for i, (contexts, target_negative, labels) in enumerate(loader, 1):\n","        # 開始訓練前要先將optimizer的梯度歸零\n","        optimizer.zero_grad()\n","        \n","        if use_cuda:\n","            contexts = contexts.cuda()\n","            target_negative = target_negative.cuda()\n","            labels = labels.cuda()\n","        \n","        pred = model(contexts, target_negative)\n","        loss = criterion(pred.float(), labels.float())\n","        batch_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if i % 500 == 0:\n","            print(f\"Epoch: {epc + 1}/{num_epochs}, Batch: {i+1}/{len(dataset)/batch_size} Loss: {batch_loss / i:.5f}\")\n","    \n","    if verbose:\n","        print(f\"Epoch: {epc + 1}/{num_epochs}, Loss: {batch_loss / i:.5f}\")\n","    \n","    lst_loss.append(batch_loss/i)"],"execution_count":64,"outputs":[{"output_type":"stream","text":["  0%|          | 0/100 [00:00<?, ?it/s]\n"],"name":"stderr"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-64-9e5c4990f068>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_negative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-53-a8384dd1d718>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, contexts, targets)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# do dot product to get output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: number of dims don't match in permute"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"id":"y0rt5W2ELLvP","executionInfo":{"elapsed":728,"status":"ok","timestamp":1606321013487,"user":{"displayName":"劉冠宏","photoUrl":"","userId":"10277899974318815441"},"user_tz":-480},"outputId":"b497edcc-fc8e-47d3-b3ff-c574d42ff581"},"source":["# visualization loss\n","\n","plt.figure(figsize=(10, 5))\n","plt.plot(lst_loss, marker='s')\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.title('Word2Vec Skip-gram Model')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x360 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"43pOYRh-MX_F","executionInfo":{"elapsed":730,"status":"ok","timestamp":1606321030038,"user":{"displayName":"劉冠宏","photoUrl":"","userId":"10277899974318815441"},"user_tz":-480},"outputId":"3de0675b-47af-462d-c927-f14a62933956"},"source":["#計算字詞相似度\n","\n","def get_similarity(word, top_k, model, word2idx, idx2word):\n","    W = (model.in_embedding.weight.data + model.out_embedding.weight.data) / 2\n","    idx = word2idx.get(word, None)\n","    \n","    if not idx:\n","        # 當出現不在字典中的字詞時，顯示Out of vocabulary error\n","        raise ValueError(\"Out of vocabulary\")\n","    else:\n","        x = W[idx]\n","        \n","        # 使用cosine相似計算字詞間的相似程度\n","        cos = torch.matmul(W, x) / (torch.sum(W * W, dim=-1) * torch.sum(x * x) + 1e-9).sqrt()\n","        _, topk = torch.topk(cos, top_k+1)\n","        \n","        for i in topk[1:]:\n","            print(f\"cosine sim={cos[int(i)]:.3f}: {idx2word[int(i)]}.\")\n","\n","get_similarity('love', 4, model, word2idx, idx2word)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cosine sim=0.407: 10-year.\n","cosine sim=0.360: scams.\n","cosine sim=0.344: perfectly.\n","cosine sim=0.341: consistent.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B_tL9g0oMcCT"},"source":[""],"execution_count":null,"outputs":[]}]}